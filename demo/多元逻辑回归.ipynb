{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f411dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77099109",
   "metadata": {},
   "source": [
    "#### 1. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2180fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>560.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>824.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>653 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1       2   3   4   5   6     7   8   9   10  11  12   13     14  \\\n",
       "0     0  30.83   0.000   0   0   9   0  1.25   0   0   1   1   0  202    0.0   \n",
       "1     1  58.67   4.460   0   0   8   1  3.04   0   0   6   1   0   43  560.0   \n",
       "2     1  24.50   0.500   0   0   8   1  1.50   0   1   0   1   0  280  824.0   \n",
       "3     0  27.83   1.540   0   0   9   0  3.75   0   0   5   0   0  100    3.0   \n",
       "4     0  20.17   5.625   0   0   9   0  1.71   0   1   0   1   2  120    0.0   \n",
       "..   ..    ...     ...  ..  ..  ..  ..   ...  ..  ..  ..  ..  ..  ...    ...   \n",
       "648   0  21.08  10.085   1   1  11   1  1.25   1   1   0   1   0  260    0.0   \n",
       "649   1  22.67   0.750   0   0   0   0  2.00   1   0   2   0   0  200  394.0   \n",
       "650   1  25.25  13.500   1   1  13   7  2.00   1   0   1   0   0  200    1.0   \n",
       "651   0  17.92   0.205   0   0  12   0  0.04   1   1   0   1   0  280  750.0   \n",
       "652   0  35.00   3.375   0   0   0   1  8.29   1   1   0   0   0    0    0.0   \n",
       "\n",
       "     15  \n",
       "0    -1  \n",
       "1    -1  \n",
       "2    -1  \n",
       "3    -1  \n",
       "4    -1  \n",
       "..   ..  \n",
       "648   1  \n",
       "649   1  \n",
       "650   1  \n",
       "651   1  \n",
       "652   1  \n",
       "\n",
       "[653 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('credit-a.csv',header = None)#不要表头\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1dc981",
   "metadata": {},
   "source": [
    "#### 2.多元回归问题，划分输入和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92b6738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 3.0830e+01, 0.0000e+00,  ..., 0.0000e+00, 2.0200e+02,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 5.8670e+01, 4.4600e+00,  ..., 0.0000e+00, 4.3000e+01,\n",
       "         5.6000e+02],\n",
       "        [1.0000e+00, 2.4500e+01, 5.0000e-01,  ..., 0.0000e+00, 2.8000e+02,\n",
       "         8.2400e+02],\n",
       "        ...,\n",
       "        [1.0000e+00, 2.5250e+01, 1.3500e+01,  ..., 0.0000e+00, 2.0000e+02,\n",
       "         1.0000e+00],\n",
       "        [0.0000e+00, 1.7920e+01, 2.0500e-01,  ..., 0.0000e+00, 2.8000e+02,\n",
       "         7.5000e+02],\n",
       "        [0.0000e+00, 3.5000e+01, 3.3750e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1] # iloc取表格的数据[行数据,列数据]，所有的行，列：直到倒数第一列\n",
    "X = torch.from_numpy(X.values).type(torch.FloatTensor) # 转换数据类型\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23574f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.iloc[:,-1:].replace(-1,0) # replace(a,b),将a换成b，二分类问题，0，1\n",
    "Y = torch.from_numpy(Y.values).type(torch.FloatTensor) # FloatTensor类型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c17c99",
   "metadata": {},
   "source": [
    "至此，X作为模型的输入，Y作为模型的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266be5f",
   "metadata": {},
   "source": [
    "#### 3. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d200f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df639dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(15,1),# 输入15，输出1\n",
    "    nn.Sigmoid() # 激活函数，实现数据的标准化映射\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d33220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=15, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14db3c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "opt = torch.optim.SGD(model.parameters(),lr)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "903aa9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "it = 0\n",
    "it = X.size(0) // batch_size # 从0开始\n",
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6baaedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: tensor(1.1263) 0.7166921898928025\n",
      "epoch: 0 loss: tensor(0.7813) 0.6998468606431854\n",
      "epoch: 0 loss: tensor(1.6626) 0.7243491577335375\n",
      "epoch: 0 loss: tensor(0.9263) 0.7228177641653905\n",
      "epoch: 0 loss: tensor(0.6837) 0.7197549770290965\n",
      "epoch: 0 loss: tensor(0.5807) 0.7090352220520674\n",
      "epoch: 0 loss: tensor(0.4490) 0.6722817764165391\n",
      "epoch: 0 loss: tensor(1.8875) 0.6983154670750383\n",
      "epoch: 0 loss: tensor(6.8921) 0.7335375191424196\n",
      "epoch: 0 loss: tensor(1.2872) 0.7350689127105666\n",
      "epoch: 0 loss: tensor(8.1834) 0.7565084226646248\n",
      "epoch: 0 loss: tensor(0.8589) 0.5987748851454824\n",
      "epoch: 0 loss: tensor(0.0466) 0.5987748851454824\n",
      "epoch: 0 loss: tensor(0.1711) 0.5987748851454824\n",
      "epoch: 0 loss: tensor(22.9528) 0.6049004594180705\n",
      "epoch: 0 loss: tensor(8.3898) 0.6294027565084227\n",
      "epoch: 0 loss: tensor(11.6199) 0.6064318529862175\n",
      "epoch: 0 loss: tensor(0.4002) 0.6033690658499234\n",
      "epoch: 0 loss: tensor(4.0028) 0.7427258805513017\n",
      "epoch: 0 loss: tensor(0.7800) 0.7457886676875957\n",
      "epoch: 1 loss: tensor(0.9806) 0.7519142419601837\n",
      "epoch: 1 loss: tensor(0.5741) 0.678407350689127\n",
      "epoch: 1 loss: tensor(1.1804) 0.7503828483920367\n",
      "epoch: 1 loss: tensor(0.7032) 0.7488514548238897\n",
      "epoch: 1 loss: tensor(0.6173) 0.7580398162327718\n",
      "epoch: 1 loss: tensor(0.5487) 0.7274119448698315\n",
      "epoch: 1 loss: tensor(0.3926) 0.6753445635528331\n",
      "epoch: 1 loss: tensor(0.7909) 0.7442572741194488\n",
      "epoch: 1 loss: tensor(1.5045) 0.6125574272588055\n",
      "epoch: 1 loss: tensor(6.8558) 0.6094946401225115\n",
      "epoch: 1 loss: tensor(0.1351) 0.6125574272588055\n",
      "epoch: 1 loss: tensor(0.0962) 0.6125574272588055\n",
      "epoch: 1 loss: tensor(0.0904) 0.6110260336906586\n",
      "epoch: 1 loss: tensor(0.2114) 0.6064318529862175\n",
      "epoch: 1 loss: tensor(22.6607) 0.6125574272588055\n",
      "epoch: 1 loss: tensor(11.5288) 0.6156202143950995\n",
      "epoch: 1 loss: tensor(23.9181) 0.5176110260336907\n",
      "epoch: 1 loss: tensor(14.4871) 0.5191424196018377\n",
      "epoch: 1 loss: tensor(8.8761) 0.7029096477794793\n",
      "epoch: 1 loss: tensor(3.9191) 0.7105666156202144\n",
      "epoch: 2 loss: tensor(0.8955) 0.7029096477794793\n",
      "epoch: 2 loss: tensor(0.5796) 0.678407350689127\n",
      "epoch: 2 loss: tensor(2.3181) 0.7120980091883614\n",
      "epoch: 2 loss: tensor(1.1071) 0.7166921898928025\n",
      "epoch: 2 loss: tensor(0.6713) 0.7105666156202144\n",
      "epoch: 2 loss: tensor(0.5754) 0.7013782542113323\n",
      "epoch: 2 loss: tensor(0.4458) 0.6722817764165391\n",
      "epoch: 2 loss: tensor(2.5054) 0.6937212863705973\n",
      "epoch: 2 loss: tensor(8.3511) 0.7136294027565084\n",
      "epoch: 2 loss: tensor(1.9498) 0.7182235834609495\n",
      "epoch: 2 loss: tensor(13.2104) 0.7212863705972435\n",
      "epoch: 2 loss: tensor(6.2753) 0.7258805513016845\n",
      "epoch: 2 loss: tensor(1.2935) 0.7335375191424196\n",
      "epoch: 2 loss: tensor(4.9506) 0.7366003062787136\n",
      "epoch: 2 loss: tensor(2.3664) 0.7611026033690659\n",
      "epoch: 2 loss: tensor(0.8873) 0.7733537519142419\n",
      "epoch: 2 loss: tensor(1.0030) 0.7611026033690659\n",
      "epoch: 2 loss: tensor(0.6332) 0.7120980091883614\n",
      "epoch: 2 loss: tensor(0.9344) 0.6294027565084227\n",
      "epoch: 2 loss: tensor(0.1778) 0.6248085758039816\n",
      "epoch: 3 loss: tensor(11.5385) 0.7243491577335375\n",
      "epoch: 3 loss: tensor(0.3384) 0.6416539050535988\n",
      "epoch: 3 loss: tensor(1.4734) 0.7473200612557427\n",
      "epoch: 3 loss: tensor(0.7197) 0.7473200612557427\n",
      "epoch: 3 loss: tensor(0.6269) 0.7473200612557427\n",
      "epoch: 3 loss: tensor(0.5448) 0.7197549770290965\n",
      "epoch: 3 loss: tensor(0.4054) 0.6738131699846861\n",
      "epoch: 3 loss: tensor(0.9299) 0.7366003062787136\n",
      "epoch: 3 loss: tensor(2.3088) 0.6294027565084227\n",
      "epoch: 3 loss: tensor(4.1181) 0.7825421133231241\n",
      "epoch: 3 loss: tensor(1.4504) 0.5957120980091883\n",
      "epoch: 3 loss: tensor(0.0593) 0.5957120980091883\n",
      "epoch: 3 loss: tensor(0.0534) 0.5957120980091883\n",
      "epoch: 3 loss: tensor(0.1778) 0.5957120980091883\n",
      "epoch: 3 loss: tensor(22.8765) 0.6094946401225115\n",
      "epoch: 3 loss: tensor(20.1170) 0.6079632465543645\n",
      "epoch: 3 loss: tensor(33.5602) 0.554364471669219\n",
      "epoch: 3 loss: tensor(45.2323) 0.47013782542113325\n",
      "epoch: 3 loss: tensor(0.7965) 0.6094946401225115\n",
      "epoch: 3 loss: tensor(0.2310) 0.6110260336906586\n",
      "epoch: 4 loss: tensor(29.4456) 0.5849923430321593\n",
      "epoch: 4 loss: tensor(25.1080) 0.42879019908116384\n",
      "epoch: 4 loss: tensor(11.3723) 0.6125574272588055\n",
      "epoch: 4 loss: tensor(14.6899) 0.6324655436447167\n",
      "epoch: 4 loss: tensor(18.3517) 0.6079632465543645\n",
      "epoch: 4 loss: tensor(0.1641) 0.5849923430321593\n",
      "epoch: 4 loss: tensor(0.2298) 0.554364471669219\n",
      "epoch: 4 loss: tensor(3.0020) 0.5972434915773354\n",
      "epoch: 4 loss: tensor(9.1100) 0.7120980091883614\n",
      "epoch: 4 loss: tensor(2.2527) 0.7136294027565084\n",
      "epoch: 4 loss: tensor(13.9294) 0.7151607963246555\n",
      "epoch: 4 loss: tensor(6.9400) 0.7228177641653905\n",
      "epoch: 4 loss: tensor(1.6037) 0.7228177641653905\n",
      "epoch: 4 loss: tensor(7.0284) 0.7335375191424196\n",
      "epoch: 4 loss: tensor(3.4327) 0.7396630934150077\n",
      "epoch: 4 loss: tensor(2.1689) 0.7427258805513017\n",
      "epoch: 4 loss: tensor(1.0346) 0.7396630934150077\n",
      "epoch: 4 loss: tensor(0.7277) 0.7182235834609495\n",
      "epoch: 4 loss: tensor(1.7249) 0.7718223583460949\n",
      "epoch: 4 loss: tensor(0.2435) 0.7366003062787136\n",
      "epoch: 5 loss: tensor(1.4109) 0.7075038284839203\n",
      "epoch: 5 loss: tensor(0.3569) 0.6493108728943339\n",
      "epoch: 5 loss: tensor(2.2461) 0.7182235834609495\n",
      "epoch: 5 loss: tensor(0.9835) 0.7228177641653905\n",
      "epoch: 5 loss: tensor(0.6581) 0.7166921898928025\n",
      "epoch: 5 loss: tensor(0.5589) 0.7059724349157733\n",
      "epoch: 5 loss: tensor(0.4295) 0.669218989280245\n",
      "epoch: 5 loss: tensor(2.0096) 0.6967840735068913\n",
      "epoch: 5 loss: tensor(7.2843) 0.7304747320061256\n",
      "epoch: 5 loss: tensor(1.4327) 0.7350689127105666\n",
      "epoch: 5 loss: tensor(9.5294) 0.7473200612557427\n",
      "epoch: 5 loss: tensor(1.4599) 0.6156202143950995\n",
      "epoch: 5 loss: tensor(0.0555) 0.6140888208269525\n",
      "epoch: 5 loss: tensor(0.1865) 0.6156202143950995\n",
      "epoch: 5 loss: tensor(14.6971) 0.7580398162327718\n",
      "epoch: 5 loss: tensor(1.1862) 0.6768759571209801\n",
      "epoch: 5 loss: tensor(1.7283) 0.6539050535987749\n",
      "epoch: 5 loss: tensor(0.4022) 0.6278713629402757\n",
      "epoch: 5 loss: tensor(7.2280) 0.7029096477794793\n",
      "epoch: 5 loss: tensor(3.3952) 0.7166921898928025\n",
      "epoch: 6 loss: tensor(1.0842) 0.7090352220520674\n",
      "epoch: 6 loss: tensor(0.7529) 0.6983154670750383\n",
      "epoch: 6 loss: tensor(1.9625) 0.7151607963246555\n",
      "epoch: 6 loss: tensor(1.0471) 0.7182235834609495\n",
      "epoch: 6 loss: tensor(0.6809) 0.7105666156202144\n",
      "epoch: 6 loss: tensor(0.5789) 0.7075038284839203\n",
      "epoch: 6 loss: tensor(0.4423) 0.6722817764165391\n",
      "epoch: 6 loss: tensor(2.2854) 0.6967840735068913\n",
      "epoch: 6 loss: tensor(8.0711) 0.7212863705972435\n",
      "epoch: 6 loss: tensor(1.6816) 0.7228177641653905\n",
      "epoch: 6 loss: tensor(12.5369) 0.7258805513016845\n",
      "epoch: 6 loss: tensor(5.3150) 0.7427258805513017\n",
      "epoch: 6 loss: tensor(0.4784) 0.7411944869831547\n",
      "epoch: 6 loss: tensor(1.3152) 0.6003062787136294\n",
      "epoch: 6 loss: tensor(23.1193) 0.6049004594180705\n",
      "epoch: 6 loss: tensor(5.5619) 0.6875957120980092\n",
      "epoch: 6 loss: tensor(1.5136) 0.6615620214395099\n",
      "epoch: 6 loss: tensor(0.4087) 0.6278713629402757\n",
      "epoch: 6 loss: tensor(6.9254) 0.7044410413476263\n",
      "epoch: 6 loss: tensor(3.1980) 0.7166921898928025\n",
      "epoch: 7 loss: tensor(1.0815) 0.7090352220520674\n",
      "epoch: 7 loss: tensor(0.7497) 0.6983154670750383\n",
      "epoch: 7 loss: tensor(1.8790) 0.7166921898928025\n",
      "epoch: 7 loss: tensor(1.0099) 0.7228177641653905\n",
      "epoch: 7 loss: tensor(0.6811) 0.7136294027565084\n",
      "epoch: 7 loss: tensor(0.5782) 0.7090352220520674\n",
      "epoch: 7 loss: tensor(0.4423) 0.6722817764165391\n",
      "epoch: 7 loss: tensor(2.1543) 0.6983154670750383\n",
      "epoch: 7 loss: tensor(7.9671) 0.7258805513016845\n",
      "epoch: 7 loss: tensor(1.5646) 0.7320061255742726\n",
      "epoch: 7 loss: tensor(11.4186) 0.7457886676875957\n",
      "epoch: 7 loss: tensor(2.0560) 0.7350689127105666\n",
      "epoch: 7 loss: tensor(0.0626) 0.7136294027565084\n",
      "epoch: 7 loss: tensor(0.2079) 0.655436447166922\n",
      "epoch: 7 loss: tensor(2.0608) 0.6998468606431854\n",
      "epoch: 7 loss: tensor(5.1829) 0.7013782542113323\n",
      "epoch: 7 loss: tensor(1.2752) 0.7059724349157733\n",
      "epoch: 7 loss: tensor(0.5717) 0.6707503828483921\n",
      "epoch: 7 loss: tensor(5.9251) 0.7151607963246555\n",
      "epoch: 7 loss: tensor(2.5528) 0.7182235834609495\n",
      "epoch: 8 loss: tensor(1.1178) 0.7182235834609495\n",
      "epoch: 8 loss: tensor(0.7813) 0.7013782542113323\n",
      "epoch: 8 loss: tensor(1.5910) 0.7243491577335375\n",
      "epoch: 8 loss: tensor(0.9026) 0.7228177641653905\n",
      "epoch: 8 loss: tensor(0.6803) 0.7243491577335375\n",
      "epoch: 8 loss: tensor(0.5760) 0.7120980091883614\n",
      "epoch: 8 loss: tensor(0.4401) 0.6738131699846861\n",
      "epoch: 8 loss: tensor(1.7701) 0.7120980091883614\n",
      "epoch: 8 loss: tensor(6.2696) 0.7335375191424196\n",
      "epoch: 8 loss: tensor(1.0899) 0.7427258805513017\n",
      "epoch: 8 loss: tensor(6.2147) 0.7687595712098009\n",
      "epoch: 8 loss: tensor(0.1302) 0.6156202143950995\n",
      "epoch: 8 loss: tensor(0.0608) 0.6140888208269525\n",
      "epoch: 8 loss: tensor(0.1898) 0.6125574272588055\n",
      "epoch: 8 loss: tensor(17.3427) 0.7304747320061256\n",
      "epoch: 8 loss: tensor(0.7759) 0.7580398162327718\n",
      "epoch: 8 loss: tensor(0.5887) 0.7366003062787136\n",
      "epoch: 8 loss: tensor(0.4726) 0.6738131699846861\n",
      "epoch: 8 loss: tensor(1.3012) 0.6294027565084227\n",
      "epoch: 8 loss: tensor(0.1801) 0.6263399693721287\n",
      "epoch: 9 loss: tensor(8.8723) 0.7105666156202144\n",
      "epoch: 9 loss: tensor(0.3304) 0.6401225114854517\n",
      "epoch: 9 loss: tensor(1.7638) 0.7320061255742726\n",
      "epoch: 9 loss: tensor(0.7987) 0.7366003062787136\n",
      "epoch: 9 loss: tensor(0.6463) 0.7350689127105666\n",
      "epoch: 9 loss: tensor(0.5506) 0.7182235834609495\n",
      "epoch: 9 loss: tensor(0.4165) 0.6722817764165391\n",
      "epoch: 9 loss: tensor(1.3011) 0.7212863705972435\n",
      "epoch: 9 loss: tensor(4.4037) 0.7595712098009189\n",
      "epoch: 9 loss: tensor(0.7443) 0.7595712098009189\n",
      "epoch: 9 loss: tensor(2.5584) 0.5957120980091883\n",
      "epoch: 9 loss: tensor(0.0547) 0.5941807044410413\n",
      "epoch: 9 loss: tensor(0.0474) 0.5941807044410413\n",
      "epoch: 9 loss: tensor(0.1737) 0.5941807044410413\n",
      "epoch: 9 loss: tensor(22.9489) 0.6049004594180705\n",
      "epoch: 9 loss: tensor(20.0942) 0.6094946401225115\n",
      "epoch: 9 loss: tensor(33.5686) 0.5650842266462481\n",
      "epoch: 9 loss: tensor(45.2187) 0.47320061255742724\n",
      "epoch: 9 loss: tensor(0.7761) 0.6094946401225115\n",
      "epoch: 9 loss: tensor(0.2316) 0.6110260336906586\n",
      "epoch: 10 loss: tensor(29.4185) 0.5865237366003063\n",
      "epoch: 10 loss: tensor(22.3279) 0.42879019908116384\n",
      "epoch: 10 loss: tensor(11.4338) 0.6156202143950995\n",
      "epoch: 10 loss: tensor(11.7646) 0.77947932618683\n",
      "epoch: 10 loss: tensor(0.3811) 0.6875957120980092\n",
      "epoch: 10 loss: tensor(0.2172) 0.6324655436447167\n",
      "epoch: 10 loss: tensor(0.2637) 0.5834609494640123\n",
      "epoch: 10 loss: tensor(1.2254) 0.6799387442572741\n",
      "epoch: 10 loss: tensor(3.6041) 0.77947932618683\n",
      "epoch: 10 loss: tensor(0.5128) 0.7825421133231241\n",
      "epoch: 10 loss: tensor(0.2840) 0.6140888208269525\n",
      "epoch: 10 loss: tensor(0.0847) 0.6094946401225115\n",
      "epoch: 10 loss: tensor(0.0835) 0.6079632465543645\n",
      "epoch: 10 loss: tensor(0.2114) 0.6049004594180705\n",
      "epoch: 10 loss: tensor(22.7111) 0.6156202143950995\n",
      "epoch: 10 loss: tensor(8.2792) 0.6339969372128637\n",
      "epoch: 10 loss: tensor(11.6234) 0.5650842266462481\n",
      "epoch: 10 loss: tensor(0.3914) 0.5911179173047473\n",
      "epoch: 10 loss: tensor(3.9481) 0.7457886676875957\n",
      "epoch: 10 loss: tensor(0.7451) 0.7473200612557427\n",
      "epoch: 11 loss: tensor(0.9499) 0.7549770290964778\n",
      "epoch: 11 loss: tensor(0.5541) 0.6753445635528331\n",
      "epoch: 11 loss: tensor(1.1886) 0.7457886676875957\n",
      "epoch: 11 loss: tensor(0.7137) 0.7503828483920367\n",
      "epoch: 11 loss: tensor(0.6087) 0.7565084226646248\n",
      "epoch: 11 loss: tensor(0.5420) 0.7274119448698315\n",
      "epoch: 11 loss: tensor(0.3682) 0.6753445635528331\n",
      "epoch: 11 loss: tensor(0.7527) 0.7503828483920367\n",
      "epoch: 11 loss: tensor(1.3632) 0.6125574272588055\n",
      "epoch: 11 loss: tensor(6.8590) 0.6094946401225115\n",
      "epoch: 11 loss: tensor(0.1464) 0.6125574272588055\n",
      "epoch: 11 loss: tensor(0.1036) 0.6125574272588055\n",
      "epoch: 11 loss: tensor(0.0961) 0.6110260336906586\n",
      "epoch: 11 loss: tensor(0.2206) 0.6064318529862175\n",
      "epoch: 11 loss: tensor(22.6705) 0.6125574272588055\n",
      "epoch: 11 loss: tensor(11.5132) 0.6156202143950995\n",
      "epoch: 11 loss: tensor(26.5665) 0.4992343032159265\n",
      "epoch: 11 loss: tensor(26.7428) 0.554364471669219\n",
      "epoch: 11 loss: tensor(3.0733) 0.7718223583460949\n",
      "epoch: 11 loss: tensor(0.2971) 0.7503828483920367\n",
      "epoch: 12 loss: tensor(1.1857) 0.6952526799387443\n",
      "epoch: 12 loss: tensor(0.2870) 0.6324655436447167\n",
      "epoch: 12 loss: tensor(2.0924) 0.7258805513016845\n",
      "epoch: 12 loss: tensor(0.9096) 0.7243491577335375\n",
      "epoch: 12 loss: tensor(0.6514) 0.7274119448698315\n",
      "epoch: 12 loss: tensor(0.5493) 0.7105666156202144\n",
      "epoch: 12 loss: tensor(0.4121) 0.6707503828483921\n",
      "epoch: 12 loss: tensor(1.6834) 0.7105666156202144\n",
      "epoch: 12 loss: tensor(6.0817) 0.7366003062787136\n",
      "epoch: 12 loss: tensor(1.0369) 0.7473200612557427\n",
      "epoch: 12 loss: tensor(5.5937) 0.7182235834609495\n",
      "epoch: 12 loss: tensor(0.0989) 0.667687595712098\n",
      "epoch: 12 loss: tensor(0.0761) 0.6600306278713629\n",
      "epoch: 12 loss: tensor(0.2207) 0.6508422664624809\n",
      "epoch: 12 loss: tensor(2.4583) 0.6983154670750383\n",
      "epoch: 12 loss: tensor(5.7802) 0.6998468606431854\n",
      "epoch: 12 loss: tensor(1.5557) 0.6983154670750383\n",
      "epoch: 12 loss: tensor(0.5681) 0.6738131699846861\n",
      "epoch: 12 loss: tensor(7.7231) 0.7013782542113323\n",
      "epoch: 12 loss: tensor(3.9441) 0.7105666156202144\n",
      "epoch: 13 loss: tensor(1.1366) 0.7059724349157733\n",
      "epoch: 13 loss: tensor(0.8100) 0.7044410413476263\n",
      "epoch: 13 loss: tensor(2.1649) 0.7075038284839203\n",
      "epoch: 13 loss: tensor(1.1682) 0.7151607963246555\n",
      "epoch: 13 loss: tensor(0.6740) 0.7105666156202144\n",
      "epoch: 13 loss: tensor(0.5754) 0.7059724349157733\n",
      "epoch: 13 loss: tensor(0.4336) 0.6753445635528331\n",
      "epoch: 13 loss: tensor(2.6764) 0.6952526799387443\n",
      "epoch: 13 loss: tensor(8.5145) 0.7120980091883614\n",
      "epoch: 13 loss: tensor(2.1540) 0.7120980091883614\n",
      "epoch: 13 loss: tensor(13.6780) 0.7182235834609495\n",
      "epoch: 13 loss: tensor(6.7253) 0.7243491577335375\n",
      "epoch: 13 loss: tensor(1.5015) 0.7228177641653905\n",
      "epoch: 13 loss: tensor(6.7580) 0.7350689127105666\n",
      "epoch: 13 loss: tensor(3.2022) 0.7442572741194488\n",
      "epoch: 13 loss: tensor(1.9775) 0.7457886676875957\n",
      "epoch: 13 loss: tensor(1.0343) 0.7488514548238897\n",
      "epoch: 13 loss: tensor(0.7258) 0.7212863705972435\n",
      "epoch: 13 loss: tensor(1.4086) 0.7105666156202144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 loss: tensor(0.2121) 0.664624808575804\n",
      "epoch: 14 loss: tensor(7.9476) 0.7304747320061256\n",
      "epoch: 14 loss: tensor(0.3911) 0.655436447166922\n",
      "epoch: 14 loss: tensor(1.6454) 0.7396630934150077\n",
      "epoch: 14 loss: tensor(0.7760) 0.7442572741194488\n",
      "epoch: 14 loss: tensor(0.6438) 0.7366003062787136\n",
      "epoch: 14 loss: tensor(0.5482) 0.7289433384379785\n",
      "epoch: 14 loss: tensor(0.4061) 0.6722817764165391\n",
      "epoch: 14 loss: tensor(1.1734) 0.7243491577335375\n",
      "epoch: 14 loss: tensor(3.7349) 0.7580398162327718\n",
      "epoch: 14 loss: tensor(0.6611) 0.7687595712098009\n",
      "epoch: 14 loss: tensor(1.5221) 0.5957120980091883\n",
      "epoch: 14 loss: tensor(0.0594) 0.5957120980091883\n",
      "epoch: 14 loss: tensor(0.0513) 0.5957120980091883\n",
      "epoch: 14 loss: tensor(0.1793) 0.5941807044410413\n",
      "epoch: 14 loss: tensor(22.9291) 0.6079632465543645\n",
      "epoch: 14 loss: tensor(20.0920) 0.6079632465543645\n",
      "epoch: 14 loss: tensor(33.5698) 0.5604900459418071\n",
      "epoch: 14 loss: tensor(45.2173) 0.4670750382848392\n",
      "epoch: 14 loss: tensor(0.7811) 0.6094946401225115\n",
      "epoch: 14 loss: tensor(0.2368) 0.6110260336906586\n",
      "epoch: 15 loss: tensor(29.4192) 0.5895865237366003\n",
      "epoch: 15 loss: tensor(22.3949) 0.42572741194486985\n",
      "epoch: 15 loss: tensor(11.4595) 0.6140888208269525\n",
      "epoch: 15 loss: tensor(11.8612) 0.7488514548238897\n",
      "epoch: 15 loss: tensor(0.6426) 0.6447166921898928\n",
      "epoch: 15 loss: tensor(0.1852) 0.6033690658499234\n",
      "epoch: 15 loss: tensor(0.2476) 0.555895865237366\n",
      "epoch: 15 loss: tensor(4.8397) 0.6094946401225115\n",
      "epoch: 15 loss: tensor(10.5291) 0.6952526799387443\n",
      "epoch: 15 loss: tensor(4.1232) 0.6906584992343032\n",
      "epoch: 15 loss: tensor(18.5177) 0.6891271056661562\n",
      "epoch: 15 loss: tensor(10.9190) 0.6967840735068913\n",
      "epoch: 15 loss: tensor(3.5875) 0.6983154670750383\n",
      "epoch: 15 loss: tensor(11.2034) 0.6952526799387443\n",
      "epoch: 15 loss: tensor(7.6880) 0.6998468606431854\n",
      "epoch: 15 loss: tensor(5.6313) 0.6998468606431854\n",
      "epoch: 15 loss: tensor(1.6919) 0.6998468606431854\n",
      "epoch: 15 loss: tensor(0.7492) 0.6983154670750383\n",
      "epoch: 15 loss: tensor(7.1089) 0.7044410413476263\n",
      "epoch: 15 loss: tensor(3.7003) 0.7136294027565084\n",
      "epoch: 16 loss: tensor(1.1950) 0.7044410413476263\n",
      "epoch: 16 loss: tensor(0.8612) 0.7075038284839203\n",
      "epoch: 16 loss: tensor(2.0296) 0.7105666156202144\n",
      "epoch: 16 loss: tensor(1.1327) 0.7166921898928025\n",
      "epoch: 16 loss: tensor(0.6717) 0.7105666156202144\n",
      "epoch: 16 loss: tensor(0.5730) 0.7029096477794793\n",
      "epoch: 16 loss: tensor(0.4343) 0.6753445635528331\n",
      "epoch: 16 loss: tensor(2.5515) 0.6952526799387443\n",
      "epoch: 16 loss: tensor(8.4014) 0.7136294027565084\n",
      "epoch: 16 loss: tensor(2.0254) 0.7136294027565084\n",
      "epoch: 16 loss: tensor(13.3810) 0.7197549770290965\n",
      "epoch: 16 loss: tensor(6.4491) 0.7243491577335375\n",
      "epoch: 16 loss: tensor(1.3744) 0.7212863705972435\n",
      "epoch: 16 loss: tensor(5.5530) 0.7366003062787136\n",
      "epoch: 16 loss: tensor(2.6546) 0.7427258805513017\n",
      "epoch: 16 loss: tensor(1.5254) 0.7580398162327718\n",
      "epoch: 16 loss: tensor(1.1653) 0.7580398162327718\n",
      "epoch: 16 loss: tensor(0.6382) 0.7136294027565084\n",
      "epoch: 16 loss: tensor(1.1590) 0.6339969372128637\n",
      "epoch: 16 loss: tensor(0.1884) 0.6309341500765697\n",
      "epoch: 17 loss: tensor(8.5711) 0.7182235834609495\n",
      "epoch: 17 loss: tensor(0.3514) 0.6447166921898928\n",
      "epoch: 17 loss: tensor(1.7364) 0.7304747320061256\n",
      "epoch: 17 loss: tensor(0.7961) 0.7411944869831547\n",
      "epoch: 17 loss: tensor(0.6452) 0.7350689127105666\n",
      "epoch: 17 loss: tensor(0.5485) 0.7212863705972435\n",
      "epoch: 17 loss: tensor(0.4095) 0.669218989280245\n",
      "epoch: 17 loss: tensor(1.2617) 0.7197549770290965\n",
      "epoch: 17 loss: tensor(4.2181) 0.7565084226646248\n",
      "epoch: 17 loss: tensor(0.7261) 0.7641653905053599\n",
      "epoch: 17 loss: tensor(2.3122) 0.5957120980091883\n",
      "epoch: 17 loss: tensor(0.0572) 0.5957120980091883\n",
      "epoch: 17 loss: tensor(0.0490) 0.5941807044410413\n",
      "epoch: 17 loss: tensor(0.1769) 0.5941807044410413\n",
      "epoch: 17 loss: tensor(22.9491) 0.6064318529862175\n",
      "epoch: 17 loss: tensor(20.0932) 0.6094946401225115\n",
      "epoch: 17 loss: tensor(33.5776) 0.5620214395099541\n",
      "epoch: 17 loss: tensor(45.2229) 0.4670750382848392\n",
      "epoch: 17 loss: tensor(0.7752) 0.6094946401225115\n",
      "epoch: 17 loss: tensor(0.2356) 0.6110260336906586\n",
      "epoch: 18 loss: tensor(29.4161) 0.5895865237366003\n",
      "epoch: 18 loss: tensor(22.3802) 0.42725880551301687\n",
      "epoch: 18 loss: tensor(11.4503) 0.6140888208269525\n",
      "epoch: 18 loss: tensor(11.8134) 0.7565084226646248\n",
      "epoch: 18 loss: tensor(0.4793) 0.6523736600306279\n",
      "epoch: 18 loss: tensor(0.1939) 0.6140888208269525\n",
      "epoch: 18 loss: tensor(0.2528) 0.5620214395099541\n",
      "epoch: 18 loss: tensor(3.2904) 0.6171516079632465\n",
      "epoch: 18 loss: tensor(9.2584) 0.7029096477794793\n",
      "epoch: 18 loss: tensor(2.5596) 0.7044410413476263\n",
      "epoch: 18 loss: tensor(14.6313) 0.7075038284839203\n",
      "epoch: 18 loss: tensor(7.5861) 0.7182235834609495\n",
      "epoch: 18 loss: tensor(1.9015) 0.7197549770290965\n",
      "epoch: 18 loss: tensor(7.7919) 0.7197549770290965\n",
      "epoch: 18 loss: tensor(4.1476) 0.7274119448698315\n",
      "epoch: 18 loss: tensor(2.7192) 0.7366003062787136\n",
      "epoch: 18 loss: tensor(1.1257) 0.7320061255742726\n",
      "epoch: 18 loss: tensor(0.7590) 0.7212863705972435\n",
      "epoch: 18 loss: tensor(2.2550) 0.7473200612557427\n",
      "epoch: 18 loss: tensor(0.4103) 0.7641653905053599\n",
      "epoch: 19 loss: tensor(1.1480) 0.7580398162327718\n",
      "epoch: 19 loss: tensor(0.5494) 0.667687595712098\n",
      "epoch: 19 loss: tensor(1.1826) 0.7534456355283308\n",
      "epoch: 19 loss: tensor(0.7214) 0.7503828483920367\n",
      "epoch: 19 loss: tensor(0.5980) 0.7580398162327718\n",
      "epoch: 19 loss: tensor(0.5381) 0.7243491577335375\n",
      "epoch: 19 loss: tensor(0.3601) 0.666156202143951\n",
      "epoch: 19 loss: tensor(0.7367) 0.7473200612557427\n",
      "epoch: 19 loss: tensor(1.2547) 0.6125574272588055\n",
      "epoch: 19 loss: tensor(6.8582) 0.6094946401225115\n",
      "epoch: 19 loss: tensor(0.1468) 0.6125574272588055\n",
      "epoch: 19 loss: tensor(0.1035) 0.6125574272588055\n",
      "epoch: 19 loss: tensor(0.0960) 0.6125574272588055\n",
      "epoch: 19 loss: tensor(0.2203) 0.6064318529862175\n",
      "epoch: 19 loss: tensor(22.6698) 0.6125574272588055\n",
      "epoch: 19 loss: tensor(11.5263) 0.6156202143950995\n",
      "epoch: 19 loss: tensor(26.5818) 0.49770290964777947\n",
      "epoch: 19 loss: tensor(26.8043) 0.552833078101072\n",
      "epoch: 19 loss: tensor(3.0763) 0.7718223583460949\n",
      "epoch: 19 loss: tensor(0.2958) 0.7488514548238897\n",
      "epoch: 20 loss: tensor(1.1889) 0.6967840735068913\n",
      "epoch: 20 loss: tensor(0.2824) 0.6339969372128637\n",
      "epoch: 20 loss: tensor(2.1617) 0.7258805513016845\n",
      "epoch: 20 loss: tensor(0.9352) 0.7228177641653905\n",
      "epoch: 20 loss: tensor(0.6520) 0.7212863705972435\n",
      "epoch: 20 loss: tensor(0.5504) 0.7105666156202144\n",
      "epoch: 20 loss: tensor(0.4141) 0.6722817764165391\n",
      "epoch: 20 loss: tensor(1.7775) 0.7075038284839203\n",
      "epoch: 20 loss: tensor(6.3014) 0.7350689127105666\n",
      "epoch: 20 loss: tensor(1.1109) 0.7411944869831547\n",
      "epoch: 20 loss: tensor(6.3337) 0.7702909647779479\n",
      "epoch: 20 loss: tensor(0.1553) 0.6094946401225115\n",
      "epoch: 20 loss: tensor(0.0621) 0.6094946401225115\n",
      "epoch: 20 loss: tensor(0.1943) 0.6079632465543645\n",
      "epoch: 20 loss: tensor(17.5444) 0.664624808575804\n",
      "epoch: 20 loss: tensor(1.0008) 0.7488514548238897\n",
      "epoch: 20 loss: tensor(0.5835) 0.7243491577335375\n",
      "epoch: 20 loss: tensor(0.4473) 0.666156202143951\n",
      "epoch: 20 loss: tensor(1.4876) 0.6339969372128637\n",
      "epoch: 20 loss: tensor(0.1948) 0.6309341500765697\n",
      "epoch: 21 loss: tensor(8.5793) 0.7151607963246555\n",
      "epoch: 21 loss: tensor(0.3449) 0.6385911179173047\n",
      "epoch: 21 loss: tensor(1.7506) 0.7304747320061256\n",
      "epoch: 21 loss: tensor(0.8019) 0.7396630934150077\n",
      "epoch: 21 loss: tensor(0.6444) 0.7320061255742726\n",
      "epoch: 21 loss: tensor(0.5457) 0.7274119448698315\n",
      "epoch: 21 loss: tensor(0.4017) 0.6768759571209801\n",
      "epoch: 21 loss: tensor(1.2517) 0.7274119448698315\n",
      "epoch: 21 loss: tensor(4.1994) 0.7580398162327718\n",
      "epoch: 21 loss: tensor(0.7288) 0.7641653905053599\n",
      "epoch: 21 loss: tensor(2.2983) 0.5957120980091883\n",
      "epoch: 21 loss: tensor(0.0602) 0.5957120980091883\n",
      "epoch: 21 loss: tensor(0.0508) 0.5941807044410413\n",
      "epoch: 21 loss: tensor(0.1806) 0.5941807044410413\n",
      "epoch: 21 loss: tensor(22.9539) 0.6079632465543645\n",
      "epoch: 21 loss: tensor(20.0840) 0.6094946401225115\n",
      "epoch: 21 loss: tensor(33.5740) 0.5666156202143952\n",
      "epoch: 21 loss: tensor(45.2166) 0.47013782542113325\n",
      "epoch: 21 loss: tensor(0.7734) 0.6094946401225115\n",
      "epoch: 21 loss: tensor(0.2402) 0.6125574272588055\n",
      "epoch: 22 loss: tensor(29.4054) 0.5880551301684533\n",
      "epoch: 22 loss: tensor(22.3676) 0.42725880551301687\n",
      "epoch: 22 loss: tensor(11.4602) 0.6171516079632465\n",
      "epoch: 22 loss: tensor(11.8210) 0.7549770290964778\n",
      "epoch: 22 loss: tensor(0.5203) 0.6508422664624809\n",
      "epoch: 22 loss: tensor(0.1862) 0.6110260336906586\n",
      "epoch: 22 loss: tensor(0.2451) 0.557427258805513\n",
      "epoch: 22 loss: tensor(3.9210) 0.6156202143950995\n",
      "epoch: 22 loss: tensor(9.7691) 0.6998468606431854\n",
      "epoch: 22 loss: tensor(3.2129) 0.6983154670750383\n",
      "epoch: 22 loss: tensor(16.1523) 0.7029096477794793\n",
      "epoch: 22 loss: tensor(8.9767) 0.7075038284839203\n",
      "epoch: 22 loss: tensor(2.5544) 0.7105666156202144\n",
      "epoch: 22 loss: tensor(9.6784) 0.7151607963246555\n",
      "epoch: 22 loss: tensor(6.4647) 0.7151607963246555\n",
      "epoch: 22 loss: tensor(4.6002) 0.7090352220520674\n",
      "epoch: 22 loss: tensor(1.3614) 0.7105666156202144\n",
      "epoch: 22 loss: tensor(0.7251) 0.7029096477794793\n",
      "epoch: 22 loss: tensor(4.8162) 0.7212863705972435\n",
      "epoch: 22 loss: tensor(2.0775) 0.7212863705972435\n",
      "epoch: 23 loss: tensor(1.1018) 0.7274119448698315\n",
      "epoch: 23 loss: tensor(0.7823) 0.7059724349157733\n",
      "epoch: 23 loss: tensor(1.3867) 0.7258805513016845\n",
      "epoch: 23 loss: tensor(0.8354) 0.7304747320061256\n",
      "epoch: 23 loss: tensor(0.6699) 0.7335375191424196\n",
      "epoch: 23 loss: tensor(0.5639) 0.7197549770290965\n",
      "epoch: 23 loss: tensor(0.4149) 0.6768759571209801\n",
      "epoch: 23 loss: tensor(1.4324) 0.7228177641653905\n",
      "epoch: 23 loss: tensor(5.4999) 0.7457886676875957\n",
      "epoch: 23 loss: tensor(0.8561) 0.7626339969372129\n",
      "epoch: 23 loss: tensor(3.7255) 0.6094946401225115\n",
      "epoch: 23 loss: tensor(0.0703) 0.6094946401225115\n",
      "epoch: 23 loss: tensor(0.0674) 0.6094946401225115\n",
      "epoch: 23 loss: tensor(0.2001) 0.6079632465543645\n",
      "epoch: 23 loss: tensor(17.5320) 0.6523736600306279\n",
      "epoch: 23 loss: tensor(1.0566) 0.7503828483920367\n",
      "epoch: 23 loss: tensor(0.5697) 0.7197549770290965\n",
      "epoch: 23 loss: tensor(0.4402) 0.663093415007657\n",
      "epoch: 23 loss: tensor(1.4967) 0.6401225114854517\n",
      "epoch: 23 loss: tensor(0.1964) 0.6309341500765697\n",
      "epoch: 24 loss: tensor(8.5752) 0.7166921898928025\n",
      "epoch: 24 loss: tensor(0.3444) 0.6385911179173047\n",
      "epoch: 24 loss: tensor(1.7529) 0.7320061255742726\n",
      "epoch: 24 loss: tensor(0.8034) 0.7396630934150077\n",
      "epoch: 24 loss: tensor(0.6441) 0.7304747320061256\n",
      "epoch: 24 loss: tensor(0.5451) 0.7274119448698315\n",
      "epoch: 24 loss: tensor(0.3998) 0.6753445635528331\n",
      "epoch: 24 loss: tensor(1.2483) 0.7274119448698315\n",
      "epoch: 24 loss: tensor(4.1901) 0.7580398162327718\n",
      "epoch: 24 loss: tensor(0.7289) 0.7641653905053599\n",
      "epoch: 24 loss: tensor(2.2888) 0.5957120980091883\n",
      "epoch: 24 loss: tensor(0.0609) 0.5957120980091883\n",
      "epoch: 24 loss: tensor(0.0513) 0.5941807044410413\n",
      "epoch: 24 loss: tensor(0.1815) 0.5941807044410413\n",
      "epoch: 24 loss: tensor(22.9548) 0.6079632465543645\n",
      "epoch: 24 loss: tensor(20.0817) 0.6094946401225115\n",
      "epoch: 24 loss: tensor(33.5734) 0.5666156202143952\n",
      "epoch: 24 loss: tensor(45.2152) 0.47013782542113325\n",
      "epoch: 24 loss: tensor(0.7730) 0.6094946401225115\n",
      "epoch: 24 loss: tensor(0.2413) 0.6125574272588055\n",
      "epoch: 25 loss: tensor(29.4033) 0.5849923430321593\n",
      "epoch: 25 loss: tensor(22.3647) 0.42725880551301687\n",
      "epoch: 25 loss: tensor(11.4630) 0.6171516079632465\n",
      "epoch: 25 loss: tensor(11.8238) 0.7549770290964778\n",
      "epoch: 25 loss: tensor(0.5364) 0.6508422664624809\n",
      "epoch: 25 loss: tensor(0.1842) 0.6110260336906586\n",
      "epoch: 25 loss: tensor(0.2431) 0.55895865237366\n",
      "epoch: 25 loss: tensor(4.1052) 0.6156202143950995\n",
      "epoch: 25 loss: tensor(9.9189) 0.6998468606431854\n",
      "epoch: 25 loss: tensor(3.4451) 0.6983154670750383\n",
      "epoch: 25 loss: tensor(16.6968) 0.6998468606431854\n",
      "epoch: 25 loss: tensor(9.4703) 0.7029096477794793\n",
      "epoch: 25 loss: tensor(2.7907) 0.7059724349157733\n",
      "epoch: 25 loss: tensor(10.0007) 0.7120980091883614\n",
      "epoch: 25 loss: tensor(6.7416) 0.7090352220520674\n",
      "epoch: 25 loss: tensor(5.1406) 0.7075038284839203\n",
      "epoch: 25 loss: tensor(1.4401) 0.7044410413476263\n",
      "epoch: 25 loss: tensor(0.7294) 0.7013782542113323\n",
      "epoch: 25 loss: tensor(5.3272) 0.7182235834609495\n",
      "epoch: 25 loss: tensor(2.4057) 0.7182235834609495\n",
      "epoch: 26 loss: tensor(1.1278) 0.7228177641653905\n",
      "epoch: 26 loss: tensor(0.8106) 0.7075038284839203\n",
      "epoch: 26 loss: tensor(1.4973) 0.7228177641653905\n",
      "epoch: 26 loss: tensor(0.8926) 0.7228177641653905\n",
      "epoch: 26 loss: tensor(0.6729) 0.7289433384379785\n",
      "epoch: 26 loss: tensor(0.5655) 0.7105666156202144\n",
      "epoch: 26 loss: tensor(0.4180) 0.678407350689127\n",
      "epoch: 26 loss: tensor(1.6473) 0.7182235834609495\n",
      "epoch: 26 loss: tensor(6.0036) 0.7350689127105666\n",
      "epoch: 26 loss: tensor(1.0177) 0.7488514548238897\n",
      "epoch: 26 loss: tensor(5.3891) 0.6983154670750383\n",
      "epoch: 26 loss: tensor(0.0960) 0.664624808575804\n",
      "epoch: 26 loss: tensor(0.0773) 0.6600306278713629\n",
      "epoch: 26 loss: tensor(0.2229) 0.6508422664624809\n",
      "epoch: 26 loss: tensor(2.5143) 0.6983154670750383\n",
      "epoch: 26 loss: tensor(5.8050) 0.6983154670750383\n",
      "epoch: 26 loss: tensor(1.5689) 0.6983154670750383\n",
      "epoch: 26 loss: tensor(0.5650) 0.6753445635528331\n",
      "epoch: 26 loss: tensor(7.8000) 0.7013782542113323\n",
      "epoch: 26 loss: tensor(4.0018) 0.7090352220520674\n",
      "epoch: 27 loss: tensor(1.1332) 0.7059724349157733\n",
      "epoch: 27 loss: tensor(0.8103) 0.7029096477794793\n",
      "epoch: 27 loss: tensor(2.1950) 0.7044410413476263\n",
      "epoch: 27 loss: tensor(1.1845) 0.7136294027565084\n",
      "epoch: 27 loss: tensor(0.6721) 0.7120980091883614\n",
      "epoch: 27 loss: tensor(0.5742) 0.7059724349157733\n",
      "epoch: 27 loss: tensor(0.4311) 0.6799387442572741\n",
      "epoch: 27 loss: tensor(2.7183) 0.6952526799387443\n",
      "epoch: 27 loss: tensor(8.5489) 0.7105666156202144\n",
      "epoch: 27 loss: tensor(2.1966) 0.7120980091883614\n",
      "epoch: 27 loss: tensor(13.7772) 0.7151607963246555\n",
      "epoch: 27 loss: tensor(6.8152) 0.7228177641653905\n",
      "epoch: 27 loss: tensor(1.5428) 0.7212863705972435\n",
      "epoch: 27 loss: tensor(6.8785) 0.7350689127105666\n",
      "epoch: 27 loss: tensor(3.3108) 0.7442572741194488\n",
      "epoch: 27 loss: tensor(2.0607) 0.7457886676875957\n",
      "epoch: 27 loss: tensor(1.0437) 0.7442572741194488\n",
      "epoch: 27 loss: tensor(0.7262) 0.7197549770290965\n",
      "epoch: 27 loss: tensor(1.5798) 0.7672281776416539\n",
      "epoch: 27 loss: tensor(0.2332) 0.6952526799387443\n",
      "epoch: 28 loss: tensor(4.8615) 0.6998468606431854\n",
      "epoch: 28 loss: tensor(0.3104) 0.6339969372128637\n",
      "epoch: 28 loss: tensor(2.8595) 0.7044410413476263\n",
      "epoch: 28 loss: tensor(1.2213) 0.7120980091883614\n",
      "epoch: 28 loss: tensor(0.6510) 0.7044410413476263\n",
      "epoch: 28 loss: tensor(0.5605) 0.7029096477794793\n",
      "epoch: 28 loss: tensor(0.4272) 0.6722817764165391\n",
      "epoch: 28 loss: tensor(2.8261) 0.6952526799387443\n",
      "epoch: 28 loss: tensor(8.6448) 0.7120980091883614\n",
      "epoch: 28 loss: tensor(2.2843) 0.7105666156202144\n",
      "epoch: 28 loss: tensor(13.9832) 0.7136294027565084\n",
      "epoch: 28 loss: tensor(7.0011) 0.7212863705972435\n",
      "epoch: 28 loss: tensor(1.6295) 0.7228177641653905\n",
      "epoch: 28 loss: tensor(7.1092) 0.7320061255742726\n",
      "epoch: 28 loss: tensor(3.5233) 0.7411944869831547\n",
      "epoch: 28 loss: tensor(2.2329) 0.7457886676875957\n",
      "epoch: 28 loss: tensor(1.0590) 0.7396630934150077\n",
      "epoch: 28 loss: tensor(0.7381) 0.7243491577335375\n",
      "epoch: 28 loss: tensor(1.7674) 0.7702909647779479\n",
      "epoch: 28 loss: tensor(0.2600) 0.7503828483920367\n",
      "epoch: 29 loss: tensor(1.3323) 0.7289433384379785\n",
      "epoch: 29 loss: tensor(0.4191) 0.6569678407350689\n",
      "epoch: 29 loss: tensor(1.5744) 0.7381316998468607\n",
      "epoch: 29 loss: tensor(0.7612) 0.7457886676875957\n",
      "epoch: 29 loss: tensor(0.6418) 0.7366003062787136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 loss: tensor(0.5489) 0.7289433384379785\n",
      "epoch: 29 loss: tensor(0.4065) 0.6768759571209801\n",
      "epoch: 29 loss: tensor(1.1106) 0.7274119448698315\n",
      "epoch: 29 loss: tensor(3.3811) 0.6722817764165391\n",
      "epoch: 29 loss: tensor(3.8032) 0.7611026033690659\n",
      "epoch: 29 loss: tensor(3.1800) 0.5957120980091883\n",
      "epoch: 29 loss: tensor(0.0606) 0.5957120980091883\n",
      "epoch: 29 loss: tensor(0.0535) 0.5957120980091883\n",
      "epoch: 29 loss: tensor(0.1808) 0.5957120980091883\n",
      "epoch: 29 loss: tensor(22.9007) 0.6079632465543645\n",
      "epoch: 29 loss: tensor(20.0514) 0.6094946401225115\n",
      "epoch: 29 loss: tensor(33.4826) 0.557427258805513\n",
      "epoch: 29 loss: tensor(45.1645) 0.4670750382848392\n",
      "epoch: 29 loss: tensor(0.7897) 0.6094946401225115\n",
      "epoch: 29 loss: tensor(0.2350) 0.6110260336906586\n",
      "epoch: 30 loss: tensor(29.3945) 0.5895865237366003\n",
      "epoch: 30 loss: tensor(22.2476) 0.42879019908116384\n",
      "epoch: 30 loss: tensor(11.4246) 0.6171516079632465\n",
      "epoch: 30 loss: tensor(11.6910) 0.77947932618683\n",
      "epoch: 30 loss: tensor(0.3342) 0.7166921898928025\n",
      "epoch: 30 loss: tensor(0.2369) 0.6493108728943339\n",
      "epoch: 30 loss: tensor(0.2679) 0.5911179173047473\n",
      "epoch: 30 loss: tensor(0.8340) 0.7044410413476263\n",
      "epoch: 30 loss: tensor(1.5189) 0.6125574272588055\n",
      "epoch: 30 loss: tensor(6.8643) 0.6094946401225115\n",
      "epoch: 30 loss: tensor(0.1472) 0.6140888208269525\n",
      "epoch: 30 loss: tensor(0.1046) 0.6125574272588055\n",
      "epoch: 30 loss: tensor(0.0969) 0.6110260336906586\n",
      "epoch: 30 loss: tensor(0.2222) 0.6064318529862175\n",
      "epoch: 30 loss: tensor(22.6734) 0.6125574272588055\n",
      "epoch: 30 loss: tensor(11.5498) 0.6156202143950995\n",
      "epoch: 30 loss: tensor(26.5914) 0.49310872894333846\n",
      "epoch: 30 loss: tensor(26.8393) 0.5467075038284839\n",
      "epoch: 30 loss: tensor(3.0720) 0.777947932618683\n",
      "epoch: 30 loss: tensor(0.2984) 0.7396630934150077\n",
      "epoch: 31 loss: tensor(1.2197) 0.6891271056661562\n",
      "epoch: 31 loss: tensor(0.2601) 0.6232771822358346\n",
      "epoch: 31 loss: tensor(3.0670) 0.7044410413476263\n",
      "epoch: 31 loss: tensor(1.3233) 0.7059724349157733\n",
      "epoch: 31 loss: tensor(0.6283) 0.7013782542113323\n",
      "epoch: 31 loss: tensor(0.5450) 0.6998468606431854\n",
      "epoch: 31 loss: tensor(0.4140) 0.6722817764165391\n",
      "epoch: 31 loss: tensor(3.1234) 0.6906584992343032\n",
      "epoch: 31 loss: tensor(8.8881) 0.7059724349157733\n",
      "epoch: 31 loss: tensor(2.5565) 0.7090352220520674\n",
      "epoch: 31 loss: tensor(14.6130) 0.7105666156202144\n",
      "epoch: 31 loss: tensor(7.5762) 0.7182235834609495\n",
      "epoch: 31 loss: tensor(1.8953) 0.7212863705972435\n",
      "epoch: 31 loss: tensor(7.7840) 0.7197549770290965\n",
      "epoch: 31 loss: tensor(4.1491) 0.7258805513016845\n",
      "epoch: 31 loss: tensor(2.7167) 0.7366003062787136\n",
      "epoch: 31 loss: tensor(1.1347) 0.7335375191424196\n",
      "epoch: 31 loss: tensor(0.7623) 0.7243491577335375\n",
      "epoch: 31 loss: tensor(2.2416) 0.7473200612557427\n",
      "epoch: 31 loss: tensor(0.4132) 0.7641653905053599\n",
      "epoch: 32 loss: tensor(1.1454) 0.7595712098009189\n",
      "epoch: 32 loss: tensor(0.5488) 0.667687595712098\n",
      "epoch: 32 loss: tensor(1.1841) 0.7549770290964778\n",
      "epoch: 32 loss: tensor(0.7233) 0.7503828483920367\n",
      "epoch: 32 loss: tensor(0.5973) 0.7580398162327718\n",
      "epoch: 32 loss: tensor(0.5378) 0.7243491577335375\n",
      "epoch: 32 loss: tensor(0.3577) 0.667687595712098\n",
      "epoch: 32 loss: tensor(0.7331) 0.7473200612557427\n",
      "epoch: 32 loss: tensor(1.2487) 0.6125574272588055\n",
      "epoch: 32 loss: tensor(6.8587) 0.6094946401225115\n",
      "epoch: 32 loss: tensor(0.1485) 0.6125574272588055\n",
      "epoch: 32 loss: tensor(0.1044) 0.6125574272588055\n",
      "epoch: 32 loss: tensor(0.0967) 0.6125574272588055\n",
      "epoch: 32 loss: tensor(0.2217) 0.6064318529862175\n",
      "epoch: 32 loss: tensor(22.6710) 0.6125574272588055\n",
      "epoch: 32 loss: tensor(11.5224) 0.6156202143950995\n",
      "epoch: 32 loss: tensor(26.5808) 0.49617151607963245\n",
      "epoch: 32 loss: tensor(26.8010) 0.5497702909647779\n",
      "epoch: 32 loss: tensor(3.0714) 0.774885145482389\n",
      "epoch: 32 loss: tensor(0.2974) 0.7473200612557427\n",
      "epoch: 33 loss: tensor(1.1999) 0.6967840735068913\n",
      "epoch: 33 loss: tensor(0.2724) 0.6294027565084227\n",
      "epoch: 33 loss: tensor(2.4164) 0.7182235834609495\n",
      "epoch: 33 loss: tensor(1.0331) 0.7212863705972435\n",
      "epoch: 33 loss: tensor(0.6523) 0.7151607963246555\n",
      "epoch: 33 loss: tensor(0.5529) 0.7044410413476263\n",
      "epoch: 33 loss: tensor(0.4165) 0.6722817764165391\n",
      "epoch: 33 loss: tensor(2.1236) 0.6967840735068913\n",
      "epoch: 33 loss: tensor(7.5714) 0.7258805513016845\n",
      "epoch: 33 loss: tensor(1.5526) 0.7320061255742726\n",
      "epoch: 33 loss: tensor(10.9434) 0.7473200612557427\n",
      "epoch: 33 loss: tensor(1.9631) 0.7136294027565084\n",
      "epoch: 33 loss: tensor(0.0655) 0.6952526799387443\n",
      "epoch: 33 loss: tensor(0.2165) 0.6569678407350689\n",
      "epoch: 33 loss: tensor(2.1259) 0.7044410413476263\n",
      "epoch: 33 loss: tensor(5.2272) 0.7059724349157733\n",
      "epoch: 33 loss: tensor(1.3114) 0.7029096477794793\n",
      "epoch: 33 loss: tensor(0.5514) 0.6738131699846861\n",
      "epoch: 33 loss: tensor(6.0937) 0.7105666156202144\n",
      "epoch: 33 loss: tensor(2.7825) 0.7182235834609495\n",
      "epoch: 34 loss: tensor(1.0969) 0.7136294027565084\n",
      "epoch: 34 loss: tensor(0.7777) 0.7044410413476263\n",
      "epoch: 34 loss: tensor(1.6734) 0.7243491577335375\n",
      "epoch: 34 loss: tensor(0.9473) 0.7243491577335375\n",
      "epoch: 34 loss: tensor(0.6768) 0.7228177641653905\n",
      "epoch: 34 loss: tensor(0.5707) 0.7120980091883614\n",
      "epoch: 34 loss: tensor(0.4272) 0.678407350689127\n",
      "epoch: 34 loss: tensor(1.8720) 0.7029096477794793\n",
      "epoch: 34 loss: tensor(6.8803) 0.7320061255742726\n",
      "epoch: 34 loss: tensor(1.3037) 0.7335375191424196\n",
      "epoch: 34 loss: tensor(8.2332) 0.7549770290964778\n",
      "epoch: 34 loss: tensor(0.8776) 0.5987748851454824\n",
      "epoch: 34 loss: tensor(0.0510) 0.6003062787136294\n",
      "epoch: 34 loss: tensor(0.1812) 0.6003062787136294\n",
      "epoch: 34 loss: tensor(22.9661) 0.6079632465543645\n",
      "epoch: 34 loss: tensor(8.3699) 0.6355283307810107\n",
      "epoch: 34 loss: tensor(11.6731) 0.6018376722817764\n",
      "epoch: 34 loss: tensor(0.3790) 0.6033690658499234\n",
      "epoch: 34 loss: tensor(3.9741) 0.7427258805513017\n",
      "epoch: 34 loss: tensor(0.8125) 0.7473200612557427\n",
      "epoch: 35 loss: tensor(0.9579) 0.7549770290964778\n",
      "epoch: 35 loss: tensor(0.5763) 0.6753445635528331\n",
      "epoch: 35 loss: tensor(1.1783) 0.7473200612557427\n",
      "epoch: 35 loss: tensor(0.7145) 0.7473200612557427\n",
      "epoch: 35 loss: tensor(0.6136) 0.7595712098009189\n",
      "epoch: 35 loss: tensor(0.5436) 0.7274119448698315\n",
      "epoch: 35 loss: tensor(0.3706) 0.6753445635528331\n",
      "epoch: 35 loss: tensor(0.7608) 0.7488514548238897\n",
      "epoch: 35 loss: tensor(1.4384) 0.6125574272588055\n",
      "epoch: 35 loss: tensor(6.8599) 0.6094946401225115\n",
      "epoch: 35 loss: tensor(0.1480) 0.6140888208269525\n",
      "epoch: 35 loss: tensor(0.1042) 0.6125574272588055\n",
      "epoch: 35 loss: tensor(0.0968) 0.6110260336906586\n",
      "epoch: 35 loss: tensor(0.2222) 0.6064318529862175\n",
      "epoch: 35 loss: tensor(22.6717) 0.6110260336906586\n",
      "epoch: 35 loss: tensor(11.4983) 0.6156202143950995\n",
      "epoch: 35 loss: tensor(26.5410) 0.4992343032159265\n",
      "epoch: 35 loss: tensor(26.6946) 0.552833078101072\n",
      "epoch: 35 loss: tensor(3.0586) 0.7733537519142419\n",
      "epoch: 35 loss: tensor(0.2985) 0.7457886676875957\n",
      "epoch: 36 loss: tensor(1.1969) 0.6967840735068913\n",
      "epoch: 36 loss: tensor(0.2773) 0.6339969372128637\n",
      "epoch: 36 loss: tensor(2.3120) 0.7197549770290965\n",
      "epoch: 36 loss: tensor(0.9936) 0.7228177641653905\n",
      "epoch: 36 loss: tensor(0.6521) 0.7151607963246555\n",
      "epoch: 36 loss: tensor(0.5516) 0.7059724349157733\n",
      "epoch: 36 loss: tensor(0.4144) 0.6738131699846861\n",
      "epoch: 36 loss: tensor(1.9763) 0.7013782542113323\n",
      "epoch: 36 loss: tensor(7.2143) 0.7304747320061256\n",
      "epoch: 36 loss: tensor(1.4212) 0.7320061255742726\n",
      "epoch: 36 loss: tensor(9.3447) 0.7488514548238897\n",
      "epoch: 36 loss: tensor(1.3748) 0.6018376722817764\n",
      "epoch: 36 loss: tensor(0.0508) 0.6018376722817764\n",
      "epoch: 36 loss: tensor(0.1823) 0.6018376722817764\n",
      "epoch: 36 loss: tensor(22.9887) 0.6094946401225115\n",
      "epoch: 36 loss: tensor(5.6469) 0.6722817764165391\n",
      "epoch: 36 loss: tensor(2.1915) 0.6140888208269525\n",
      "epoch: 36 loss: tensor(0.3683) 0.6110260336906586\n",
      "epoch: 36 loss: tensor(7.7910) 0.7044410413476263\n",
      "epoch: 36 loss: tensor(3.7544) 0.7136294027565084\n",
      "epoch: 37 loss: tensor(1.0611) 0.7105666156202144\n",
      "epoch: 37 loss: tensor(0.7476) 0.6983154670750383\n",
      "epoch: 37 loss: tensor(2.1124) 0.7090352220520674\n",
      "epoch: 37 loss: tensor(1.1215) 0.7182235834609495\n",
      "epoch: 37 loss: tensor(0.6752) 0.7120980091883614\n",
      "epoch: 37 loss: tensor(0.5740) 0.7044410413476263\n",
      "epoch: 37 loss: tensor(0.4290) 0.6799387442572741\n",
      "epoch: 37 loss: tensor(2.4856) 0.6983154670750383\n",
      "epoch: 37 loss: tensor(8.3237) 0.7136294027565084\n",
      "epoch: 37 loss: tensor(1.9601) 0.7151607963246555\n",
      "epoch: 37 loss: tensor(13.2281) 0.7228177641653905\n",
      "epoch: 37 loss: tensor(6.2928) 0.7258805513016845\n",
      "epoch: 37 loss: tensor(1.2981) 0.7320061255742726\n",
      "epoch: 37 loss: tensor(4.9477) 0.7366003062787136\n",
      "epoch: 37 loss: tensor(2.3716) 0.7641653905053599\n",
      "epoch: 37 loss: tensor(0.8747) 0.7687595712098009\n",
      "epoch: 37 loss: tensor(0.9901) 0.7656967840735069\n",
      "epoch: 37 loss: tensor(0.6281) 0.7243491577335375\n",
      "epoch: 37 loss: tensor(0.8998) 0.6309341500765697\n",
      "epoch: 37 loss: tensor(0.1912) 0.6248085758039816\n",
      "epoch: 38 loss: tensor(11.4999) 0.7335375191424196\n",
      "epoch: 38 loss: tensor(0.3292) 0.6385911179173047\n",
      "epoch: 38 loss: tensor(1.5005) 0.7488514548238897\n",
      "epoch: 38 loss: tensor(0.7321) 0.7457886676875957\n",
      "epoch: 38 loss: tensor(0.6235) 0.7488514548238897\n",
      "epoch: 38 loss: tensor(0.5385) 0.7258805513016845\n",
      "epoch: 38 loss: tensor(0.3871) 0.6738131699846861\n",
      "epoch: 38 loss: tensor(0.8995) 0.7427258805513017\n",
      "epoch: 38 loss: tensor(2.2405) 0.6309341500765697\n",
      "epoch: 38 loss: tensor(4.1349) 0.77947932618683\n",
      "epoch: 38 loss: tensor(1.4104) 0.5957120980091883\n",
      "epoch: 38 loss: tensor(0.0660) 0.5957120980091883\n",
      "epoch: 38 loss: tensor(0.0579) 0.5957120980091883\n",
      "epoch: 38 loss: tensor(0.1868) 0.5957120980091883\n",
      "epoch: 38 loss: tensor(22.8842) 0.6079632465543645\n",
      "epoch: 38 loss: tensor(20.0836) 0.6110260336906586\n",
      "epoch: 38 loss: tensor(33.5402) 0.552833078101072\n",
      "epoch: 38 loss: tensor(45.2163) 0.4686064318529862\n",
      "epoch: 38 loss: tensor(0.7923) 0.6079632465543645\n",
      "epoch: 38 loss: tensor(0.2411) 0.6140888208269525\n",
      "epoch: 39 loss: tensor(29.4167) 0.5880551301684533\n",
      "epoch: 39 loss: tensor(25.0675) 0.42572741194486985\n",
      "epoch: 39 loss: tensor(11.3888) 0.6110260336906586\n",
      "epoch: 39 loss: tensor(14.6950) 0.6355283307810107\n",
      "epoch: 39 loss: tensor(18.3501) 0.6140888208269525\n",
      "epoch: 39 loss: tensor(0.1522) 0.5834609494640123\n",
      "epoch: 39 loss: tensor(0.2173) 0.554364471669219\n",
      "epoch: 39 loss: tensor(2.9812) 0.5957120980091883\n",
      "epoch: 39 loss: tensor(9.0780) 0.7136294027565084\n",
      "epoch: 39 loss: tensor(2.2554) 0.7151607963246555\n",
      "epoch: 39 loss: tensor(13.9265) 0.7136294027565084\n",
      "epoch: 39 loss: tensor(6.9424) 0.7212863705972435\n",
      "epoch: 39 loss: tensor(1.6019) 0.7228177641653905\n",
      "epoch: 39 loss: tensor(7.0269) 0.7304747320061256\n",
      "epoch: 39 loss: tensor(3.4323) 0.7396630934150077\n",
      "epoch: 39 loss: tensor(2.1493) 0.7457886676875957\n",
      "epoch: 39 loss: tensor(1.0566) 0.7411944869831547\n",
      "epoch: 39 loss: tensor(0.7187) 0.7228177641653905\n",
      "epoch: 39 loss: tensor(1.6830) 0.7718223583460949\n",
      "epoch: 39 loss: tensor(0.2586) 0.7105666156202144\n",
      "epoch: 40 loss: tensor(1.6396) 0.6799387442572741\n",
      "epoch: 40 loss: tensor(0.2931) 0.6094946401225115\n",
      "epoch: 40 loss: tensor(6.6055) 0.6875957120980092\n",
      "epoch: 40 loss: tensor(2.8816) 0.6814701378254211\n",
      "epoch: 40 loss: tensor(0.5197) 0.6906584992343032\n",
      "epoch: 40 loss: tensor(0.5287) 0.6830015313935681\n",
      "epoch: 40 loss: tensor(0.4112) 0.6539050535987749\n",
      "epoch: 40 loss: tensor(7.0821) 0.6738131699846861\n",
      "epoch: 40 loss: tensor(13.3516) 0.6952526799387443\n",
      "epoch: 40 loss: tensor(6.2218) 0.6906584992343032\n",
      "epoch: 40 loss: tensor(20.9160) 0.6830015313935681\n",
      "epoch: 40 loss: tensor(15.1268) 0.6799387442572741\n",
      "epoch: 40 loss: tensor(6.3599) 0.6799387442572741\n",
      "epoch: 40 loss: tensor(17.0278) 0.678407350689127\n",
      "epoch: 40 loss: tensor(11.6333) 0.6799387442572741\n",
      "epoch: 40 loss: tensor(6.9352) 0.6830015313935681\n",
      "epoch: 40 loss: tensor(3.0668) 0.6830015313935681\n",
      "epoch: 40 loss: tensor(0.8604) 0.6952526799387443\n",
      "epoch: 40 loss: tensor(14.7137) 0.6799387442572741\n",
      "epoch: 40 loss: tensor(9.9990) 0.678407350689127\n",
      "epoch: 41 loss: tensor(1.1979) 0.6830015313935681\n",
      "epoch: 41 loss: tensor(0.8892) 0.6875957120980092\n",
      "epoch: 41 loss: tensor(5.1824) 0.6860643185298622\n",
      "epoch: 41 loss: tensor(2.5758) 0.6814701378254211\n",
      "epoch: 41 loss: tensor(0.5625) 0.6891271056661562\n",
      "epoch: 41 loss: tensor(0.5485) 0.6845329249617151\n",
      "epoch: 41 loss: tensor(0.4248) 0.6584992343032159\n",
      "epoch: 41 loss: tensor(6.9882) 0.6768759571209801\n",
      "epoch: 41 loss: tensor(12.4624) 0.6906584992343032\n",
      "epoch: 41 loss: tensor(5.8063) 0.6906584992343032\n",
      "epoch: 41 loss: tensor(20.5924) 0.6830015313935681\n",
      "epoch: 41 loss: tensor(14.2408) 0.6875957120980092\n",
      "epoch: 41 loss: tensor(5.8003) 0.6830015313935681\n",
      "epoch: 41 loss: tensor(15.0688) 0.6830015313935681\n",
      "epoch: 41 loss: tensor(10.8953) 0.6830015313935681\n",
      "epoch: 41 loss: tensor(6.8920) 0.6814701378254211\n",
      "epoch: 41 loss: tensor(2.7070) 0.6891271056661562\n",
      "epoch: 41 loss: tensor(0.8331) 0.6952526799387443\n",
      "epoch: 41 loss: tensor(13.5326) 0.6830015313935681\n",
      "epoch: 41 loss: tensor(8.4392) 0.6845329249617151\n",
      "epoch: 42 loss: tensor(1.1836) 0.6845329249617151\n",
      "epoch: 42 loss: tensor(0.8654) 0.6906584992343032\n",
      "epoch: 42 loss: tensor(4.4337) 0.6891271056661562\n",
      "epoch: 42 loss: tensor(2.2324) 0.6860643185298622\n",
      "epoch: 42 loss: tensor(0.5827) 0.6967840735068913\n",
      "epoch: 42 loss: tensor(0.5515) 0.6891271056661562\n",
      "epoch: 42 loss: tensor(0.4292) 0.6569678407350689\n",
      "epoch: 42 loss: tensor(6.1557) 0.6799387442572741\n",
      "epoch: 42 loss: tensor(11.5041) 0.6983154670750383\n",
      "epoch: 42 loss: tensor(5.3732) 0.6937212863705973\n",
      "epoch: 42 loss: tensor(20.2539) 0.6845329249617151\n",
      "epoch: 42 loss: tensor(13.3265) 0.6875957120980092\n",
      "epoch: 42 loss: tensor(5.2179) 0.6875957120980092\n",
      "epoch: 42 loss: tensor(13.3787) 0.6921898928024502\n",
      "epoch: 42 loss: tensor(9.6856) 0.6891271056661562\n",
      "epoch: 42 loss: tensor(6.8449) 0.6875957120980092\n",
      "epoch: 42 loss: tensor(2.2972) 0.6891271056661562\n",
      "epoch: 42 loss: tensor(0.8063) 0.6952526799387443\n",
      "epoch: 42 loss: tensor(11.3413) 0.6891271056661562\n",
      "epoch: 42 loss: tensor(6.5146) 0.6952526799387443\n",
      "epoch: 43 loss: tensor(1.2276) 0.6860643185298622\n",
      "epoch: 43 loss: tensor(0.8931) 0.6952526799387443\n",
      "epoch: 43 loss: tensor(3.4960) 0.6891271056661562\n",
      "epoch: 43 loss: tensor(1.8441) 0.6891271056661562\n",
      "epoch: 43 loss: tensor(0.5958) 0.6952526799387443\n",
      "epoch: 43 loss: tensor(0.5472) 0.6906584992343032\n",
      "epoch: 43 loss: tensor(0.4293) 0.6569678407350689\n",
      "epoch: 43 loss: tensor(4.9877) 0.6845329249617151\n",
      "epoch: 43 loss: tensor(10.4043) 0.6952526799387443\n",
      "epoch: 43 loss: tensor(4.3938) 0.6937212863705973\n",
      "epoch: 43 loss: tensor(19.1422) 0.6906584992343032\n",
      "epoch: 43 loss: tensor(11.7460) 0.6967840735068913\n",
      "epoch: 43 loss: tensor(3.8800) 0.6967840735068913\n",
      "epoch: 43 loss: tensor(11.5943) 0.6952526799387443\n",
      "epoch: 43 loss: tensor(8.0238) 0.6998468606431854\n",
      "epoch: 43 loss: tensor(5.8528) 0.6967840735068913\n",
      "epoch: 43 loss: tensor(1.7931) 0.6937212863705973\n",
      "epoch: 43 loss: tensor(0.7678) 0.6983154670750383\n",
      "epoch: 43 loss: tensor(7.9076) 0.7044410413476263\n",
      "epoch: 43 loss: tensor(4.1926) 0.7075038284839203\n",
      "epoch: 44 loss: tensor(1.2239) 0.7029096477794793\n",
      "epoch: 44 loss: tensor(0.8766) 0.7044410413476263\n",
      "epoch: 44 loss: tensor(2.3100) 0.7029096477794793\n",
      "epoch: 44 loss: tensor(1.2488) 0.7090352220520674\n",
      "epoch: 44 loss: tensor(0.6737) 0.7029096477794793\n",
      "epoch: 44 loss: tensor(0.5842) 0.7029096477794793\n",
      "epoch: 44 loss: tensor(0.4516) 0.6707503828483921\n",
      "epoch: 44 loss: tensor(3.0092) 0.6952526799387443\n",
      "epoch: 44 loss: tensor(8.7888) 0.7105666156202144\n",
      "epoch: 44 loss: tensor(2.4383) 0.7105666156202144\n",
      "epoch: 44 loss: tensor(14.3496) 0.7120980091883614\n",
      "epoch: 44 loss: tensor(7.3287) 0.7182235834609495\n",
      "epoch: 44 loss: tensor(1.7843) 0.7182235834609495\n",
      "epoch: 44 loss: tensor(7.5050) 0.7243491577335375\n",
      "epoch: 44 loss: tensor(3.8886) 0.7335375191424196\n",
      "epoch: 44 loss: tensor(2.5386) 0.7381316998468607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 loss: tensor(1.0814) 0.7335375191424196\n",
      "epoch: 44 loss: tensor(0.7664) 0.7182235834609495\n",
      "epoch: 44 loss: tensor(2.0769) 0.7565084226646248\n",
      "epoch: 44 loss: tensor(0.3191) 0.7702909647779479\n",
      "epoch: 45 loss: tensor(1.2015) 0.7534456355283308\n",
      "epoch: 45 loss: tensor(0.5209) 0.6707503828483921\n",
      "epoch: 45 loss: tensor(1.2072) 0.7503828483920367\n",
      "epoch: 45 loss: tensor(0.7124) 0.7519142419601837\n",
      "epoch: 45 loss: tensor(0.6036) 0.7565084226646248\n",
      "epoch: 45 loss: tensor(0.5449) 0.7258805513016845\n",
      "epoch: 45 loss: tensor(0.3834) 0.667687595712098\n",
      "epoch: 45 loss: tensor(0.7631) 0.7519142419601837\n",
      "epoch: 45 loss: tensor(1.3426) 0.6140888208269525\n",
      "epoch: 45 loss: tensor(6.8541) 0.6110260336906586\n",
      "epoch: 45 loss: tensor(0.1369) 0.6125574272588055\n",
      "epoch: 45 loss: tensor(0.0961) 0.6156202143950995\n",
      "epoch: 45 loss: tensor(0.0903) 0.6110260336906586\n",
      "epoch: 45 loss: tensor(0.2119) 0.6079632465543645\n",
      "epoch: 45 loss: tensor(22.6593) 0.6110260336906586\n",
      "epoch: 45 loss: tensor(11.5447) 0.6156202143950995\n",
      "epoch: 45 loss: tensor(26.5777) 0.5099540581929556\n",
      "epoch: 45 loss: tensor(26.7906) 0.5620214395099541\n",
      "epoch: 45 loss: tensor(3.0806) 0.7718223583460949\n",
      "epoch: 45 loss: tensor(0.2807) 0.7549770290964778\n",
      "epoch: 46 loss: tensor(1.1458) 0.7182235834609495\n",
      "epoch: 46 loss: tensor(0.3278) 0.6447166921898928\n",
      "epoch: 46 loss: tensor(1.5744) 0.7427258805513017\n",
      "epoch: 46 loss: tensor(0.7446) 0.7457886676875957\n",
      "epoch: 46 loss: tensor(0.6335) 0.7381316998468607\n",
      "epoch: 46 loss: tensor(0.5471) 0.7243491577335375\n",
      "epoch: 46 loss: tensor(0.4093) 0.6722817764165391\n",
      "epoch: 46 loss: tensor(1.0402) 0.7320061255742726\n",
      "epoch: 46 loss: tensor(2.9546) 0.6385911179173047\n",
      "epoch: 46 loss: tensor(3.9560) 0.7672281776416539\n",
      "epoch: 46 loss: tensor(2.3704) 0.5957120980091883\n",
      "epoch: 46 loss: tensor(0.0581) 0.5957120980091883\n",
      "epoch: 46 loss: tensor(0.0520) 0.5957120980091883\n",
      "epoch: 46 loss: tensor(0.1779) 0.5957120980091883\n",
      "epoch: 46 loss: tensor(22.8939) 0.6079632465543645\n",
      "epoch: 46 loss: tensor(20.0960) 0.6094946401225115\n",
      "epoch: 46 loss: tensor(33.5466) 0.557427258805513\n",
      "epoch: 46 loss: tensor(45.2192) 0.47013782542113325\n",
      "epoch: 46 loss: tensor(0.7901) 0.6094946401225115\n",
      "epoch: 46 loss: tensor(0.2322) 0.6110260336906586\n",
      "epoch: 47 loss: tensor(29.4281) 0.5849923430321593\n",
      "epoch: 47 loss: tensor(22.4094) 0.42879019908116384\n",
      "epoch: 47 loss: tensor(11.4526) 0.6110260336906586\n",
      "epoch: 47 loss: tensor(11.8397) 0.7488514548238897\n",
      "epoch: 47 loss: tensor(0.6300) 0.6462480857580398\n",
      "epoch: 47 loss: tensor(0.1910) 0.6033690658499234\n",
      "epoch: 47 loss: tensor(0.2553) 0.55895865237366\n",
      "epoch: 47 loss: tensor(4.7819) 0.6140888208269525\n",
      "epoch: 47 loss: tensor(10.4859) 0.6952526799387443\n",
      "epoch: 47 loss: tensor(4.0616) 0.6937212863705973\n",
      "epoch: 47 loss: tensor(18.4238) 0.6891271056661562\n",
      "epoch: 47 loss: tensor(10.7878) 0.6998468606431854\n",
      "epoch: 47 loss: tensor(3.5230) 0.6983154670750383\n",
      "epoch: 47 loss: tensor(11.1074) 0.6952526799387443\n",
      "epoch: 47 loss: tensor(7.6025) 0.7044410413476263\n",
      "epoch: 47 loss: tensor(5.5982) 0.7029096477794793\n",
      "epoch: 47 loss: tensor(1.6585) 0.6998468606431854\n",
      "epoch: 47 loss: tensor(0.7529) 0.6983154670750383\n",
      "epoch: 47 loss: tensor(6.9973) 0.7059724349157733\n",
      "epoch: 47 loss: tensor(3.5969) 0.7136294027565084\n",
      "epoch: 48 loss: tensor(1.1966) 0.7059724349157733\n",
      "epoch: 48 loss: tensor(0.8564) 0.7059724349157733\n",
      "epoch: 48 loss: tensor(1.9956) 0.7120980091883614\n",
      "epoch: 48 loss: tensor(1.1094) 0.7182235834609495\n",
      "epoch: 48 loss: tensor(0.6781) 0.7105666156202144\n",
      "epoch: 48 loss: tensor(0.5807) 0.7029096477794793\n",
      "epoch: 48 loss: tensor(0.4453) 0.6753445635528331\n",
      "epoch: 48 loss: tensor(2.4972) 0.6937212863705973\n",
      "epoch: 48 loss: tensor(8.3380) 0.7151607963246555\n",
      "epoch: 48 loss: tensor(1.9524) 0.7166921898928025\n",
      "epoch: 48 loss: tensor(13.2187) 0.7243491577335375\n",
      "epoch: 48 loss: tensor(6.2809) 0.7258805513016845\n",
      "epoch: 48 loss: tensor(1.2962) 0.7350689127105666\n",
      "epoch: 48 loss: tensor(4.9601) 0.7350689127105666\n",
      "epoch: 48 loss: tensor(2.3691) 0.7626339969372129\n",
      "epoch: 48 loss: tensor(0.8836) 0.7718223583460949\n",
      "epoch: 48 loss: tensor(1.0041) 0.7611026033690659\n",
      "epoch: 48 loss: tensor(0.6314) 0.7166921898928025\n",
      "epoch: 48 loss: tensor(0.9249) 0.6294027565084227\n",
      "epoch: 48 loss: tensor(0.1810) 0.6248085758039816\n",
      "epoch: 49 loss: tensor(11.5198) 0.7274119448698315\n",
      "epoch: 49 loss: tensor(0.3361) 0.6431852986217458\n",
      "epoch: 49 loss: tensor(1.4793) 0.7473200612557427\n",
      "epoch: 49 loss: tensor(0.7251) 0.7473200612557427\n",
      "epoch: 49 loss: tensor(0.6245) 0.7488514548238897\n",
      "epoch: 49 loss: tensor(0.5434) 0.7228177641653905\n",
      "epoch: 49 loss: tensor(0.4014) 0.6753445635528331\n",
      "epoch: 49 loss: tensor(0.9181) 0.7396630934150077\n",
      "epoch: 49 loss: tensor(2.2780) 0.6309341500765697\n",
      "epoch: 49 loss: tensor(4.1187) 0.7840735068912711\n",
      "epoch: 49 loss: tensor(1.4297) 0.5957120980091883\n",
      "epoch: 49 loss: tensor(0.0605) 0.5957120980091883\n",
      "epoch: 49 loss: tensor(0.0543) 0.5957120980091883\n",
      "epoch: 49 loss: tensor(0.1803) 0.5957120980091883\n",
      "epoch: 49 loss: tensor(22.8760) 0.6079632465543645\n",
      "epoch: 49 loss: tensor(20.1002) 0.6079632465543645\n",
      "epoch: 49 loss: tensor(33.5499) 0.552833078101072\n",
      "epoch: 49 loss: tensor(45.2287) 0.4686064318529862\n",
      "epoch: 49 loss: tensor(0.7944) 0.6094946401225115\n",
      "epoch: 49 loss: tensor(0.2335) 0.6110260336906586\n",
      "epoch: 50 loss: tensor(29.4345) 0.5849923430321593\n",
      "epoch: 50 loss: tensor(25.0931) 0.42879019908116384\n",
      "epoch: 50 loss: tensor(11.3767) 0.6125574272588055\n",
      "epoch: 50 loss: tensor(14.6908) 0.6355283307810107\n",
      "epoch: 50 loss: tensor(18.3489) 0.6140888208269525\n",
      "epoch: 50 loss: tensor(0.1610) 0.5865237366003063\n",
      "epoch: 50 loss: tensor(0.2272) 0.552833078101072\n",
      "epoch: 50 loss: tensor(2.9914) 0.5987748851454824\n",
      "epoch: 50 loss: tensor(9.0951) 0.7105666156202144\n",
      "epoch: 50 loss: tensor(2.2501) 0.7120980091883614\n",
      "epoch: 50 loss: tensor(13.9251) 0.7151607963246555\n",
      "epoch: 50 loss: tensor(6.9341) 0.7228177641653905\n",
      "epoch: 50 loss: tensor(1.6011) 0.7228177641653905\n",
      "epoch: 50 loss: tensor(7.0243) 0.7320061255742726\n",
      "epoch: 50 loss: tensor(3.4251) 0.7411944869831547\n",
      "epoch: 50 loss: tensor(2.1621) 0.7442572741194488\n",
      "epoch: 50 loss: tensor(1.0373) 0.7411944869831547\n",
      "epoch: 50 loss: tensor(0.7264) 0.7197549770290965\n",
      "epoch: 50 loss: tensor(1.7092) 0.7718223583460949\n",
      "epoch: 50 loss: tensor(0.2460) 0.7335375191424196\n",
      "epoch: 51 loss: tensor(1.4279) 0.7029096477794793\n",
      "epoch: 51 loss: tensor(0.3389) 0.6462480857580398\n",
      "epoch: 51 loss: tensor(2.5761) 0.7105666156202144\n",
      "epoch: 51 loss: tensor(1.1145) 0.7182235834609495\n",
      "epoch: 51 loss: tensor(0.6544) 0.7136294027565084\n",
      "epoch: 51 loss: tensor(0.5609) 0.6983154670750383\n",
      "epoch: 51 loss: tensor(0.4303) 0.6722817764165391\n",
      "epoch: 51 loss: tensor(2.4516) 0.6937212863705973\n",
      "epoch: 51 loss: tensor(8.2771) 0.7166921898928025\n",
      "epoch: 51 loss: tensor(1.8881) 0.7182235834609495\n",
      "epoch: 51 loss: tensor(13.0666) 0.7289433384379785\n",
      "epoch: 51 loss: tensor(6.0836) 0.7243491577335375\n",
      "epoch: 51 loss: tensor(1.1768) 0.7366003062787136\n",
      "epoch: 51 loss: tensor(4.4140) 0.7320061255742726\n",
      "epoch: 51 loss: tensor(2.1182) 0.7565084226646248\n",
      "epoch: 51 loss: tensor(0.9547) 0.7473200612557427\n",
      "epoch: 51 loss: tensor(0.8801) 0.7534456355283308\n",
      "epoch: 51 loss: tensor(0.6295) 0.7136294027565084\n",
      "epoch: 51 loss: tensor(1.2659) 0.6385911179173047\n",
      "epoch: 51 loss: tensor(0.1896) 0.6339969372128637\n",
      "epoch: 52 loss: tensor(8.4256) 0.7243491577335375\n",
      "epoch: 52 loss: tensor(0.3620) 0.6539050535987749\n",
      "epoch: 52 loss: tensor(1.7125) 0.7320061255742726\n",
      "epoch: 52 loss: tensor(0.7926) 0.7427258805513017\n",
      "epoch: 52 loss: tensor(0.6439) 0.7350689127105666\n",
      "epoch: 52 loss: tensor(0.5496) 0.7243491577335375\n",
      "epoch: 52 loss: tensor(0.4117) 0.6707503828483921\n",
      "epoch: 52 loss: tensor(1.2411) 0.7212863705972435\n",
      "epoch: 52 loss: tensor(4.1044) 0.7595712098009189\n",
      "epoch: 52 loss: tensor(0.7111) 0.7626339969372129\n",
      "epoch: 52 loss: tensor(2.1572) 0.5957120980091883\n",
      "epoch: 52 loss: tensor(0.0563) 0.5957120980091883\n",
      "epoch: 52 loss: tensor(0.0487) 0.5941807044410413\n",
      "epoch: 52 loss: tensor(0.1765) 0.5941807044410413\n",
      "epoch: 52 loss: tensor(22.9432) 0.6064318529862175\n",
      "epoch: 52 loss: tensor(20.0995) 0.6094946401225115\n",
      "epoch: 52 loss: tensor(33.5795) 0.5635528330781011\n",
      "epoch: 52 loss: tensor(45.2250) 0.4686064318529862\n",
      "epoch: 52 loss: tensor(0.7754) 0.6094946401225115\n",
      "epoch: 52 loss: tensor(0.2348) 0.6110260336906586\n",
      "epoch: 53 loss: tensor(29.4182) 0.5849923430321593\n",
      "epoch: 53 loss: tensor(22.3903) 0.42725880551301687\n",
      "epoch: 53 loss: tensor(11.4539) 0.6140888208269525\n",
      "epoch: 53 loss: tensor(11.8305) 0.7519142419601837\n",
      "epoch: 53 loss: tensor(0.5704) 0.6493108728943339\n",
      "epoch: 53 loss: tensor(0.1896) 0.6079632465543645\n",
      "epoch: 53 loss: tensor(0.2519) 0.555895865237366\n",
      "epoch: 53 loss: tensor(4.3993) 0.6171516079632465\n",
      "epoch: 53 loss: tensor(10.1664) 0.6967840735068913\n",
      "epoch: 53 loss: tensor(3.7183) 0.6952526799387443\n",
      "epoch: 53 loss: tensor(17.3397) 0.6937212863705973\n",
      "epoch: 53 loss: tensor(10.0536) 0.7013782542113323\n",
      "epoch: 53 loss: tensor(3.0735) 0.7029096477794793\n",
      "epoch: 53 loss: tensor(10.3770) 0.7044410413476263\n",
      "epoch: 53 loss: tensor(7.0502) 0.7075038284839203\n",
      "epoch: 53 loss: tensor(5.3118) 0.7059724349157733\n",
      "epoch: 53 loss: tensor(1.5227) 0.7029096477794793\n",
      "epoch: 53 loss: tensor(0.7547) 0.6998468606431854\n",
      "epoch: 53 loss: tensor(5.9152) 0.7105666156202144\n",
      "epoch: 53 loss: tensor(2.8676) 0.7166921898928025\n",
      "epoch: 54 loss: tensor(1.1609) 0.7151607963246555\n",
      "epoch: 54 loss: tensor(0.8317) 0.7044410413476263\n",
      "epoch: 54 loss: tensor(1.6867) 0.7228177641653905\n",
      "epoch: 54 loss: tensor(0.9726) 0.7228177641653905\n",
      "epoch: 54 loss: tensor(0.6785) 0.7182235834609495\n",
      "epoch: 54 loss: tensor(0.5750) 0.7120980091883614\n",
      "epoch: 54 loss: tensor(0.4355) 0.6768759571209801\n",
      "epoch: 54 loss: tensor(1.9814) 0.6983154670750383\n",
      "epoch: 54 loss: tensor(7.2217) 0.7304747320061256\n",
      "epoch: 54 loss: tensor(1.4189) 0.7335375191424196\n",
      "epoch: 54 loss: tensor(9.3918) 0.7473200612557427\n",
      "epoch: 54 loss: tensor(1.3949) 0.6018376722817764\n",
      "epoch: 54 loss: tensor(0.0483) 0.6018376722817764\n",
      "epoch: 54 loss: tensor(0.1774) 0.6018376722817764\n",
      "epoch: 54 loss: tensor(22.9808) 0.6079632465543645\n",
      "epoch: 54 loss: tensor(5.6346) 0.667687595712098\n",
      "epoch: 54 loss: tensor(2.1118) 0.6202143950995406\n",
      "epoch: 54 loss: tensor(0.3800) 0.6110260336906586\n",
      "epoch: 54 loss: tensor(7.6989) 0.7075038284839203\n",
      "epoch: 54 loss: tensor(3.6712) 0.7136294027565084\n",
      "epoch: 55 loss: tensor(1.0686) 0.7090352220520674\n",
      "epoch: 55 loss: tensor(0.7461) 0.6983154670750383\n",
      "epoch: 55 loss: tensor(2.0879) 0.7120980091883614\n",
      "epoch: 55 loss: tensor(1.1033) 0.7182235834609495\n",
      "epoch: 55 loss: tensor(0.6779) 0.7120980091883614\n",
      "epoch: 55 loss: tensor(0.5788) 0.7029096477794793\n",
      "epoch: 55 loss: tensor(0.4396) 0.6753445635528331\n",
      "epoch: 55 loss: tensor(2.4529) 0.6921898928024502\n",
      "epoch: 55 loss: tensor(8.2751) 0.7166921898928025\n",
      "epoch: 55 loss: tensor(1.8996) 0.7182235834609495\n",
      "epoch: 55 loss: tensor(13.0936) 0.7304747320061256\n",
      "epoch: 55 loss: tensor(6.1242) 0.7258805513016845\n",
      "epoch: 55 loss: tensor(1.2060) 0.7335375191424196\n",
      "epoch: 55 loss: tensor(4.5449) 0.7304747320061256\n",
      "epoch: 55 loss: tensor(2.1770) 0.7580398162327718\n",
      "epoch: 55 loss: tensor(0.9250) 0.7473200612557427\n",
      "epoch: 55 loss: tensor(0.8914) 0.7580398162327718\n",
      "epoch: 55 loss: tensor(0.6360) 0.7166921898928025\n",
      "epoch: 55 loss: tensor(1.1897) 0.6339969372128637\n",
      "epoch: 55 loss: tensor(0.1878) 0.6309341500765697\n",
      "epoch: 56 loss: tensor(8.5291) 0.7228177641653905\n",
      "epoch: 56 loss: tensor(0.3548) 0.6523736600306279\n",
      "epoch: 56 loss: tensor(1.7278) 0.7320061255742726\n",
      "epoch: 56 loss: tensor(0.7964) 0.7427258805513017\n",
      "epoch: 56 loss: tensor(0.6439) 0.7350689127105666\n",
      "epoch: 56 loss: tensor(0.5495) 0.7243491577335375\n",
      "epoch: 56 loss: tensor(0.4117) 0.6707503828483921\n",
      "epoch: 56 loss: tensor(1.2540) 0.7212863705972435\n",
      "epoch: 56 loss: tensor(4.1786) 0.7595712098009189\n",
      "epoch: 56 loss: tensor(0.7202) 0.7656967840735069\n",
      "epoch: 56 loss: tensor(2.2631) 0.5957120980091883\n",
      "epoch: 56 loss: tensor(0.0562) 0.5957120980091883\n",
      "epoch: 56 loss: tensor(0.0486) 0.5941807044410413\n",
      "epoch: 56 loss: tensor(0.1766) 0.5941807044410413\n",
      "epoch: 56 loss: tensor(22.9453) 0.6064318529862175\n",
      "epoch: 56 loss: tensor(20.0944) 0.6094946401225115\n",
      "epoch: 56 loss: tensor(33.5748) 0.5650842266462481\n",
      "epoch: 56 loss: tensor(45.2249) 0.4686064318529862\n",
      "epoch: 56 loss: tensor(0.7748) 0.6094946401225115\n",
      "epoch: 56 loss: tensor(0.2349) 0.6110260336906586\n",
      "epoch: 57 loss: tensor(29.4153) 0.5865237366003063\n",
      "epoch: 57 loss: tensor(22.3822) 0.42879019908116384\n",
      "epoch: 57 loss: tensor(11.4513) 0.6140888208269525\n",
      "epoch: 57 loss: tensor(11.8200) 0.7549770290964778\n",
      "epoch: 57 loss: tensor(0.5069) 0.6523736600306279\n",
      "epoch: 57 loss: tensor(0.1927) 0.6140888208269525\n",
      "epoch: 57 loss: tensor(0.2534) 0.55895865237366\n",
      "epoch: 57 loss: tensor(3.7200) 0.6202143950995406\n",
      "epoch: 57 loss: tensor(9.6091) 0.7013782542113323\n",
      "epoch: 57 loss: tensor(2.9441) 0.7029096477794793\n",
      "epoch: 57 loss: tensor(15.5311) 0.7044410413476263\n",
      "epoch: 57 loss: tensor(8.4042) 0.7120980091883614\n",
      "epoch: 57 loss: tensor(2.2860) 0.7151607963246555\n",
      "epoch: 57 loss: tensor(8.7583) 0.7166921898928025\n",
      "epoch: 57 loss: tensor(5.0421) 0.7228177641653905\n",
      "epoch: 57 loss: tensor(3.6841) 0.7243491577335375\n",
      "epoch: 57 loss: tensor(1.2509) 0.7182235834609495\n",
      "epoch: 57 loss: tensor(0.7737) 0.7075038284839203\n",
      "epoch: 57 loss: tensor(3.6698) 0.7381316998468607\n",
      "epoch: 57 loss: tensor(1.0711) 0.7396630934150077\n",
      "epoch: 58 loss: tensor(1.0717) 0.7411944869831547\n",
      "epoch: 58 loss: tensor(0.7013) 0.6998468606431854\n",
      "epoch: 58 loss: tensor(1.1282) 0.7457886676875957\n",
      "epoch: 58 loss: tensor(0.7193) 0.7457886676875957\n",
      "epoch: 58 loss: tensor(0.6373) 0.7503828483920367\n",
      "epoch: 58 loss: tensor(0.5530) 0.7289433384379785\n",
      "epoch: 58 loss: tensor(0.3983) 0.6753445635528331\n",
      "epoch: 58 loss: tensor(0.8836) 0.7381316998468607\n",
      "epoch: 58 loss: tensor(2.1333) 0.6309341500765697\n",
      "epoch: 58 loss: tensor(4.1541) 0.77947932618683\n",
      "epoch: 58 loss: tensor(1.2465) 0.5957120980091883\n",
      "epoch: 58 loss: tensor(0.0637) 0.5957120980091883\n",
      "epoch: 58 loss: tensor(0.0569) 0.5957120980091883\n",
      "epoch: 58 loss: tensor(0.1844) 0.5957120980091883\n",
      "epoch: 58 loss: tensor(22.8705) 0.6094946401225115\n",
      "epoch: 58 loss: tensor(20.0808) 0.6110260336906586\n",
      "epoch: 58 loss: tensor(33.5214) 0.552833078101072\n",
      "epoch: 58 loss: tensor(45.2074) 0.4670750382848392\n",
      "epoch: 58 loss: tensor(0.7954) 0.6094946401225115\n",
      "epoch: 58 loss: tensor(0.2370) 0.6125574272588055\n",
      "epoch: 59 loss: tensor(29.4176) 0.5849923430321593\n",
      "epoch: 59 loss: tensor(22.3986) 0.4241960183767228\n",
      "epoch: 59 loss: tensor(11.4637) 0.6140888208269525\n",
      "epoch: 59 loss: tensor(11.8755) 0.7442572741194488\n",
      "epoch: 59 loss: tensor(0.7376) 0.6447166921898928\n",
      "epoch: 59 loss: tensor(0.1837) 0.6033690658499234\n",
      "epoch: 59 loss: tensor(0.2477) 0.555895865237366\n",
      "epoch: 59 loss: tensor(5.1615) 0.6110260336906586\n",
      "epoch: 59 loss: tensor(10.7941) 0.6967840735068913\n",
      "epoch: 59 loss: tensor(4.4166) 0.6937212863705973\n",
      "epoch: 59 loss: tensor(19.1761) 0.6875957120980092\n",
      "epoch: 59 loss: tensor(11.7801) 0.6937212863705973\n",
      "epoch: 59 loss: tensor(3.9013) 0.6983154670750383\n",
      "epoch: 59 loss: tensor(11.6279) 0.6952526799387443\n",
      "epoch: 59 loss: tensor(8.0436) 0.6998468606431854\n",
      "epoch: 59 loss: tensor(5.8540) 0.6967840735068913\n",
      "epoch: 59 loss: tensor(1.8052) 0.6983154670750383\n",
      "epoch: 59 loss: tensor(0.7544) 0.6967840735068913\n",
      "epoch: 59 loss: tensor(7.9180) 0.7013782542113323\n",
      "epoch: 59 loss: tensor(4.2309) 0.7059724349157733\n",
      "epoch: 60 loss: tensor(1.2076) 0.7029096477794793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 loss: tensor(0.8744) 0.7044410413476263\n",
      "epoch: 60 loss: tensor(2.3202) 0.7029096477794793\n",
      "epoch: 60 loss: tensor(1.2647) 0.7090352220520674\n",
      "epoch: 60 loss: tensor(0.6657) 0.7029096477794793\n",
      "epoch: 60 loss: tensor(0.5755) 0.7044410413476263\n",
      "epoch: 60 loss: tensor(0.4380) 0.6738131699846861\n",
      "epoch: 60 loss: tensor(3.0083) 0.6952526799387443\n",
      "epoch: 60 loss: tensor(8.7858) 0.7105666156202144\n",
      "epoch: 60 loss: tensor(2.4514) 0.7105666156202144\n",
      "epoch: 60 loss: tensor(14.3758) 0.7090352220520674\n",
      "epoch: 60 loss: tensor(7.3548) 0.7182235834609495\n",
      "epoch: 60 loss: tensor(1.7946) 0.7197549770290965\n",
      "epoch: 60 loss: tensor(7.5316) 0.7258805513016845\n",
      "epoch: 60 loss: tensor(3.9116) 0.7381316998468607\n",
      "epoch: 60 loss: tensor(2.5444) 0.7381316998468607\n",
      "epoch: 60 loss: tensor(1.0955) 0.7366003062787136\n",
      "epoch: 60 loss: tensor(0.7594) 0.7228177641653905\n",
      "epoch: 60 loss: tensor(2.0730) 0.7549770290964778\n",
      "epoch: 60 loss: tensor(0.3366) 0.7687595712098009\n",
      "epoch: 61 loss: tensor(1.1885) 0.7534456355283308\n",
      "epoch: 61 loss: tensor(0.5175) 0.666156202143951\n",
      "epoch: 61 loss: tensor(1.2143) 0.7503828483920367\n",
      "epoch: 61 loss: tensor(0.7182) 0.7503828483920367\n",
      "epoch: 61 loss: tensor(0.6020) 0.7565084226646248\n",
      "epoch: 61 loss: tensor(0.5420) 0.7212863705972435\n",
      "epoch: 61 loss: tensor(0.3719) 0.6722817764165391\n",
      "epoch: 61 loss: tensor(0.7495) 0.7488514548238897\n",
      "epoch: 61 loss: tensor(1.3199) 0.6140888208269525\n",
      "epoch: 61 loss: tensor(6.8566) 0.6094946401225115\n",
      "epoch: 61 loss: tensor(0.1431) 0.6125574272588055\n",
      "epoch: 61 loss: tensor(0.1000) 0.6140888208269525\n",
      "epoch: 61 loss: tensor(0.0935) 0.6110260336906586\n",
      "epoch: 61 loss: tensor(0.2175) 0.6079632465543645\n",
      "epoch: 61 loss: tensor(22.6647) 0.6125574272588055\n",
      "epoch: 61 loss: tensor(11.5272) 0.6156202143950995\n",
      "epoch: 61 loss: tensor(26.5725) 0.5068912710566615\n",
      "epoch: 61 loss: tensor(26.7766) 0.5620214395099541\n",
      "epoch: 61 loss: tensor(3.0677) 0.7733537519142419\n",
      "epoch: 61 loss: tensor(0.2891) 0.7549770290964778\n",
      "epoch: 62 loss: tensor(1.1639) 0.7090352220520674\n",
      "epoch: 62 loss: tensor(0.3070) 0.6339969372128637\n",
      "epoch: 62 loss: tensor(1.7897) 0.7304747320061256\n",
      "epoch: 62 loss: tensor(0.8091) 0.7396630934150077\n",
      "epoch: 62 loss: tensor(0.6428) 0.7320061255742726\n",
      "epoch: 62 loss: tensor(0.5476) 0.7212863705972435\n",
      "epoch: 62 loss: tensor(0.4095) 0.6738131699846861\n",
      "epoch: 62 loss: tensor(1.2892) 0.7166921898928025\n",
      "epoch: 62 loss: tensor(4.3860) 0.7580398162327718\n",
      "epoch: 62 loss: tensor(0.7466) 0.7611026033690659\n",
      "epoch: 62 loss: tensor(2.5562) 0.5957120980091883\n",
      "epoch: 62 loss: tensor(0.0567) 0.5957120980091883\n",
      "epoch: 62 loss: tensor(0.0487) 0.5941807044410413\n",
      "epoch: 62 loss: tensor(0.1775) 0.5941807044410413\n",
      "epoch: 62 loss: tensor(22.9507) 0.6064318529862175\n",
      "epoch: 62 loss: tensor(20.0781) 0.6079632465543645\n",
      "epoch: 62 loss: tensor(33.5575) 0.5635528330781011\n",
      "epoch: 62 loss: tensor(45.2134) 0.4670750382848392\n",
      "epoch: 62 loss: tensor(0.7733) 0.6094946401225115\n",
      "epoch: 62 loss: tensor(0.2361) 0.6110260336906586\n",
      "epoch: 63 loss: tensor(29.4027) 0.5895865237366003\n",
      "epoch: 63 loss: tensor(22.3094) 0.42725880551301687\n",
      "epoch: 63 loss: tensor(11.4435) 0.6171516079632465\n",
      "epoch: 63 loss: tensor(11.7733) 0.7733537519142419\n",
      "epoch: 63 loss: tensor(0.3913) 0.6814701378254211\n",
      "epoch: 63 loss: tensor(0.2075) 0.6278713629402757\n",
      "epoch: 63 loss: tensor(0.2569) 0.5758039816232772\n",
      "epoch: 63 loss: tensor(1.4462) 0.6722817764165391\n",
      "epoch: 63 loss: tensor(4.8453) 0.7595712098009189\n",
      "epoch: 63 loss: tensor(0.7622) 0.7611026033690659\n",
      "epoch: 63 loss: tensor(2.7054) 0.5957120980091883\n",
      "epoch: 63 loss: tensor(0.0591) 0.5957120980091883\n",
      "epoch: 63 loss: tensor(0.0501) 0.5941807044410413\n",
      "epoch: 63 loss: tensor(0.1806) 0.5941807044410413\n",
      "epoch: 63 loss: tensor(22.9557) 0.6079632465543645\n",
      "epoch: 63 loss: tensor(20.0645) 0.6094946401225115\n",
      "epoch: 63 loss: tensor(33.5448) 0.5650842266462481\n",
      "epoch: 63 loss: tensor(45.2006) 0.47166921898928027\n",
      "epoch: 63 loss: tensor(0.7718) 0.6094946401225115\n",
      "epoch: 63 loss: tensor(0.2398) 0.6125574272588055\n",
      "epoch: 64 loss: tensor(29.3892) 0.5849923430321593\n",
      "epoch: 64 loss: tensor(22.2845) 0.42725880551301687\n",
      "epoch: 64 loss: tensor(11.4453) 0.6186830015313936\n",
      "epoch: 64 loss: tensor(11.7494) 0.7825421133231241\n",
      "epoch: 64 loss: tensor(0.3688) 0.6921898928024502\n",
      "epoch: 64 loss: tensor(0.2120) 0.6339969372128637\n",
      "epoch: 64 loss: tensor(0.2533) 0.5819295558958653\n",
      "epoch: 64 loss: tensor(1.1054) 0.6768759571209801\n",
      "epoch: 64 loss: tensor(3.0099) 0.6431852986217458\n",
      "epoch: 64 loss: tensor(4.0349) 0.7687595712098009\n",
      "epoch: 64 loss: tensor(1.9769) 0.5957120980091883\n",
      "epoch: 64 loss: tensor(0.0667) 0.5957120980091883\n",
      "epoch: 64 loss: tensor(0.0574) 0.5957120980091883\n",
      "epoch: 64 loss: tensor(0.1887) 0.5957120980091883\n",
      "epoch: 64 loss: tensor(22.9040) 0.6064318529862175\n",
      "epoch: 64 loss: tensor(20.0733) 0.6110260336906586\n",
      "epoch: 64 loss: tensor(33.5506) 0.554364471669219\n",
      "epoch: 64 loss: tensor(45.2148) 0.4655436447166922\n",
      "epoch: 64 loss: tensor(0.7859) 0.6094946401225115\n",
      "epoch: 64 loss: tensor(0.2454) 0.6140888208269525\n",
      "epoch: 65 loss: tensor(29.4062) 0.5865237366003063\n",
      "epoch: 65 loss: tensor(25.0565) 0.4226646248085758\n",
      "epoch: 65 loss: tensor(11.3986) 0.6110260336906586\n",
      "epoch: 65 loss: tensor(14.7074) 0.6401225114854517\n",
      "epoch: 65 loss: tensor(18.3840) 0.6110260336906586\n",
      "epoch: 65 loss: tensor(0.1476) 0.5803981623277182\n",
      "epoch: 65 loss: tensor(0.2125) 0.5497702909647779\n",
      "epoch: 65 loss: tensor(2.9719) 0.5972434915773354\n",
      "epoch: 65 loss: tensor(9.0645) 0.7136294027565084\n",
      "epoch: 65 loss: tensor(2.2552) 0.7151607963246555\n",
      "epoch: 65 loss: tensor(13.9231) 0.7136294027565084\n",
      "epoch: 65 loss: tensor(6.9402) 0.7212863705972435\n",
      "epoch: 65 loss: tensor(1.5999) 0.7212863705972435\n",
      "epoch: 65 loss: tensor(7.0233) 0.7320061255742726\n",
      "epoch: 65 loss: tensor(3.4282) 0.7381316998468607\n",
      "epoch: 65 loss: tensor(2.1405) 0.7442572741194488\n",
      "epoch: 65 loss: tensor(1.0645) 0.7396630934150077\n",
      "epoch: 65 loss: tensor(0.7159) 0.7243491577335375\n",
      "epoch: 65 loss: tensor(1.6642) 0.7718223583460949\n",
      "epoch: 65 loss: tensor(0.2643) 0.7075038284839203\n",
      "epoch: 66 loss: tensor(1.8095) 0.678407350689127\n",
      "epoch: 66 loss: tensor(0.2889) 0.6110260336906586\n",
      "epoch: 66 loss: tensor(6.7141) 0.6891271056661562\n",
      "epoch: 66 loss: tensor(2.9307) 0.6814701378254211\n",
      "epoch: 66 loss: tensor(0.5168) 0.6906584992343032\n",
      "epoch: 66 loss: tensor(0.5270) 0.6814701378254211\n",
      "epoch: 66 loss: tensor(0.4057) 0.655436447166922\n",
      "epoch: 66 loss: tensor(7.0899) 0.6768759571209801\n",
      "epoch: 66 loss: tensor(13.4597) 0.6952526799387443\n",
      "epoch: 66 loss: tensor(6.2837) 0.6906584992343032\n",
      "epoch: 66 loss: tensor(20.9679) 0.6830015313935681\n",
      "epoch: 66 loss: tensor(15.2469) 0.6799387442572741\n",
      "epoch: 66 loss: tensor(6.4352) 0.6814701378254211\n",
      "epoch: 66 loss: tensor(17.1295) 0.678407350689127\n",
      "epoch: 66 loss: tensor(11.7357) 0.6814701378254211\n",
      "epoch: 66 loss: tensor(6.9402) 0.6845329249617151\n",
      "epoch: 66 loss: tensor(3.1182) 0.6830015313935681\n",
      "epoch: 66 loss: tensor(0.8601) 0.6952526799387443\n",
      "epoch: 66 loss: tensor(14.8600) 0.6799387442572741\n",
      "epoch: 66 loss: tensor(10.2099) 0.678407350689127\n",
      "epoch: 67 loss: tensor(1.1735) 0.6860643185298622\n",
      "epoch: 67 loss: tensor(0.8754) 0.6875957120980092\n",
      "epoch: 67 loss: tensor(5.3077) 0.6875957120980092\n",
      "epoch: 67 loss: tensor(2.6325) 0.6814701378254211\n",
      "epoch: 67 loss: tensor(0.5595) 0.6891271056661562\n",
      "epoch: 67 loss: tensor(0.5472) 0.6845329249617151\n",
      "epoch: 67 loss: tensor(0.4198) 0.6615620214395099\n",
      "epoch: 67 loss: tensor(6.9982) 0.6799387442572741\n",
      "epoch: 67 loss: tensor(12.5929) 0.6906584992343032\n",
      "epoch: 67 loss: tensor(5.8721) 0.6921898928024502\n",
      "epoch: 67 loss: tensor(20.6546) 0.6845329249617151\n",
      "epoch: 67 loss: tensor(14.3857) 0.6860643185298622\n",
      "epoch: 67 loss: tensor(5.8913) 0.6830015313935681\n",
      "epoch: 67 loss: tensor(15.3244) 0.6830015313935681\n",
      "epoch: 67 loss: tensor(11.0163) 0.6830015313935681\n",
      "epoch: 67 loss: tensor(6.8970) 0.6830015313935681\n",
      "epoch: 67 loss: tensor(2.7657) 0.6891271056661562\n",
      "epoch: 67 loss: tensor(0.8313) 0.6952526799387443\n",
      "epoch: 67 loss: tensor(13.7165) 0.6830015313935681\n",
      "epoch: 67 loss: tensor(8.6987) 0.6830015313935681\n",
      "epoch: 68 loss: tensor(1.1763) 0.6875957120980092\n",
      "epoch: 68 loss: tensor(0.8670) 0.6921898928024502\n",
      "epoch: 68 loss: tensor(4.5547) 0.6891271056661562\n",
      "epoch: 68 loss: tensor(2.2930) 0.6860643185298622\n",
      "epoch: 68 loss: tensor(0.5771) 0.6967840735068913\n",
      "epoch: 68 loss: tensor(0.5485) 0.6875957120980092\n",
      "epoch: 68 loss: tensor(0.4237) 0.6600306278713629\n",
      "epoch: 68 loss: tensor(6.2348) 0.6799387442572741\n",
      "epoch: 68 loss: tensor(11.6438) 0.6967840735068913\n",
      "epoch: 68 loss: tensor(5.4413) 0.6952526799387443\n",
      "epoch: 68 loss: tensor(20.3092) 0.6860643185298622\n",
      "epoch: 68 loss: tensor(13.4657) 0.6875957120980092\n",
      "epoch: 68 loss: tensor(5.3121) 0.6860643185298622\n",
      "epoch: 68 loss: tensor(13.6598) 0.6891271056661562\n",
      "epoch: 68 loss: tensor(10.2050) 0.6875957120980092\n",
      "epoch: 68 loss: tensor(6.8534) 0.6860643185298622\n",
      "epoch: 68 loss: tensor(2.3748) 0.6891271056661562\n",
      "epoch: 68 loss: tensor(0.8116) 0.6952526799387443\n",
      "epoch: 68 loss: tensor(11.6554) 0.6875957120980092\n",
      "epoch: 68 loss: tensor(6.8282) 0.6921898928024502\n",
      "epoch: 69 loss: tensor(1.2262) 0.6875957120980092\n",
      "epoch: 69 loss: tensor(0.9004) 0.6937212863705973\n",
      "epoch: 69 loss: tensor(3.6417) 0.6875957120980092\n",
      "epoch: 69 loss: tensor(1.9182) 0.6875957120980092\n",
      "epoch: 69 loss: tensor(0.5882) 0.6952526799387443\n",
      "epoch: 69 loss: tensor(0.5433) 0.6906584992343032\n",
      "epoch: 69 loss: tensor(0.4234) 0.6584992343032159\n",
      "epoch: 69 loss: tensor(5.2075) 0.6845329249617151\n",
      "epoch: 69 loss: tensor(10.5812) 0.6937212863705973\n",
      "epoch: 69 loss: tensor(4.6035) 0.6937212863705973\n",
      "epoch: 69 loss: tensor(19.3268) 0.6860643185298622\n",
      "epoch: 69 loss: tensor(12.0494) 0.6937212863705973\n",
      "epoch: 69 loss: tensor(4.1001) 0.6983154670750383\n",
      "epoch: 69 loss: tensor(11.8944) 0.6952526799387443\n",
      "epoch: 69 loss: tensor(8.2789) 0.6998468606431854\n",
      "epoch: 69 loss: tensor(5.9815) 0.6952526799387443\n",
      "epoch: 69 loss: tensor(1.8745) 0.6952526799387443\n",
      "epoch: 69 loss: tensor(0.7772) 0.6983154670750383\n",
      "epoch: 69 loss: tensor(8.3402) 0.7013782542113323\n",
      "epoch: 69 loss: tensor(4.5043) 0.7044410413476263\n",
      "epoch: 70 loss: tensor(1.2272) 0.6998468606431854\n",
      "epoch: 70 loss: tensor(0.8872) 0.7029096477794793\n",
      "epoch: 70 loss: tensor(2.4552) 0.7029096477794793\n",
      "epoch: 70 loss: tensor(1.3547) 0.7044410413476263\n",
      "epoch: 70 loss: tensor(0.6456) 0.6983154670750383\n",
      "epoch: 70 loss: tensor(0.5661) 0.7013782542113323\n",
      "epoch: 70 loss: tensor(0.4385) 0.6722817764165391\n",
      "epoch: 70 loss: tensor(3.3126) 0.6921898928024502\n",
      "epoch: 70 loss: tensor(9.0379) 0.7044410413476263\n",
      "epoch: 70 loss: tensor(2.7137) 0.7029096477794793\n",
      "epoch: 70 loss: tensor(14.9905) 0.7059724349157733\n",
      "epoch: 70 loss: tensor(7.9122) 0.7151607963246555\n",
      "epoch: 70 loss: tensor(2.0561) 0.7166921898928025\n",
      "epoch: 70 loss: tensor(8.1916) 0.7182235834609495\n",
      "epoch: 70 loss: tensor(4.5238) 0.7243491577335375\n",
      "epoch: 70 loss: tensor(3.0341) 0.7258805513016845\n",
      "epoch: 70 loss: tensor(1.1737) 0.7320061255742726\n",
      "epoch: 70 loss: tensor(0.7943) 0.7151607963246555\n",
      "epoch: 70 loss: tensor(2.8219) 0.7473200612557427\n",
      "epoch: 70 loss: tensor(0.6223) 0.7457886676875957\n",
      "epoch: 71 loss: tensor(1.0888) 0.7595712098009189\n",
      "epoch: 71 loss: tensor(0.6343) 0.678407350689127\n",
      "epoch: 71 loss: tensor(1.1130) 0.7473200612557427\n",
      "epoch: 71 loss: tensor(0.7128) 0.7503828483920367\n",
      "epoch: 71 loss: tensor(0.6110) 0.7565084226646248\n",
      "epoch: 71 loss: tensor(0.5492) 0.7274119448698315\n",
      "epoch: 71 loss: tensor(0.3840) 0.6753445635528331\n",
      "epoch: 71 loss: tensor(0.7645) 0.7473200612557427\n",
      "epoch: 71 loss: tensor(1.3852) 0.6140888208269525\n",
      "epoch: 71 loss: tensor(6.8552) 0.6110260336906586\n",
      "epoch: 71 loss: tensor(0.1389) 0.6125574272588055\n",
      "epoch: 71 loss: tensor(0.0970) 0.6156202143950995\n",
      "epoch: 71 loss: tensor(0.0912) 0.6110260336906586\n",
      "epoch: 71 loss: tensor(0.2142) 0.6079632465543645\n",
      "epoch: 71 loss: tensor(22.6605) 0.6110260336906586\n",
      "epoch: 71 loss: tensor(11.5298) 0.6140888208269525\n",
      "epoch: 71 loss: tensor(26.5660) 0.5130168453292496\n",
      "epoch: 71 loss: tensor(26.7532) 0.5620214395099541\n",
      "epoch: 71 loss: tensor(3.0670) 0.7733537519142419\n",
      "epoch: 71 loss: tensor(0.2833) 0.7580398162327718\n",
      "epoch: 72 loss: tensor(1.1493) 0.7197549770290965\n",
      "epoch: 72 loss: tensor(0.3238) 0.6447166921898928\n",
      "epoch: 72 loss: tensor(1.6163) 0.7427258805513017\n",
      "epoch: 72 loss: tensor(0.7588) 0.7442572741194488\n",
      "epoch: 72 loss: tensor(0.6348) 0.7366003062787136\n",
      "epoch: 72 loss: tensor(0.5470) 0.7258805513016845\n",
      "epoch: 72 loss: tensor(0.4083) 0.6738131699846861\n",
      "epoch: 72 loss: tensor(1.0806) 0.7274119448698315\n",
      "epoch: 72 loss: tensor(3.2030) 0.6493108728943339\n",
      "epoch: 72 loss: tensor(3.8890) 0.7641653905053599\n",
      "epoch: 72 loss: tensor(2.7445) 0.5957120980091883\n",
      "epoch: 72 loss: tensor(0.0587) 0.5957120980091883\n",
      "epoch: 72 loss: tensor(0.0523) 0.5957120980091883\n",
      "epoch: 72 loss: tensor(0.1796) 0.5957120980091883\n",
      "epoch: 72 loss: tensor(22.8960) 0.6079632465543645\n",
      "epoch: 72 loss: tensor(20.0762) 0.6094946401225115\n",
      "epoch: 72 loss: tensor(33.5150) 0.557427258805513\n",
      "epoch: 72 loss: tensor(45.2057) 0.4686064318529862\n",
      "epoch: 72 loss: tensor(0.7890) 0.6094946401225115\n",
      "epoch: 72 loss: tensor(0.2339) 0.6110260336906586\n",
      "epoch: 73 loss: tensor(29.4091) 0.5849923430321593\n",
      "epoch: 73 loss: tensor(22.3221) 0.43032159264931086\n",
      "epoch: 73 loss: tensor(11.4409) 0.6156202143950995\n",
      "epoch: 73 loss: tensor(11.7787) 0.776416539050536\n",
      "epoch: 73 loss: tensor(0.4011) 0.6738131699846861\n",
      "epoch: 73 loss: tensor(0.2083) 0.6278713629402757\n",
      "epoch: 73 loss: tensor(0.2609) 0.5803981623277182\n",
      "epoch: 73 loss: tensor(1.6103) 0.664624808575804\n",
      "epoch: 73 loss: tensor(5.9051) 0.7473200612557427\n",
      "epoch: 73 loss: tensor(0.8680) 0.7626339969372129\n",
      "epoch: 73 loss: tensor(3.9113) 0.6309341500765697\n",
      "epoch: 73 loss: tensor(0.0768) 0.6309341500765697\n",
      "epoch: 73 loss: tensor(0.0736) 0.6294027565084227\n",
      "epoch: 73 loss: tensor(0.2098) 0.6248085758039816\n",
      "epoch: 73 loss: tensor(11.7231) 0.7335375191424196\n",
      "epoch: 73 loss: tensor(1.9272) 0.7488514548238897\n",
      "epoch: 73 loss: tensor(0.6971) 0.7320061255742726\n",
      "epoch: 73 loss: tensor(0.5021) 0.6768759571209801\n",
      "epoch: 73 loss: tensor(1.7390) 0.6845329249617151\n",
      "epoch: 73 loss: tensor(0.2089) 0.6569678407350689\n",
      "epoch: 74 loss: tensor(8.0352) 0.7289433384379785\n",
      "epoch: 74 loss: tensor(0.3760) 0.6523736600306279\n",
      "epoch: 74 loss: tensor(1.6655) 0.7411944869831547\n",
      "epoch: 74 loss: tensor(0.7847) 0.7442572741194488\n",
      "epoch: 74 loss: tensor(0.6411) 0.7366003062787136\n",
      "epoch: 74 loss: tensor(0.5476) 0.7304747320061256\n",
      "epoch: 74 loss: tensor(0.4050) 0.6799387442572741\n",
      "epoch: 74 loss: tensor(1.1727) 0.7243491577335375\n",
      "epoch: 74 loss: tensor(3.7561) 0.7611026033690659\n",
      "epoch: 74 loss: tensor(0.6666) 0.7672281776416539\n",
      "epoch: 74 loss: tensor(1.5928) 0.5957120980091883\n",
      "epoch: 74 loss: tensor(0.0592) 0.5957120980091883\n",
      "epoch: 74 loss: tensor(0.0512) 0.5957120980091883\n",
      "epoch: 74 loss: tensor(0.1805) 0.5941807044410413\n",
      "epoch: 74 loss: tensor(22.9298) 0.6064318529862175\n",
      "epoch: 74 loss: tensor(20.0892) 0.6094946401225115\n",
      "epoch: 74 loss: tensor(33.5663) 0.5620214395099541\n",
      "epoch: 74 loss: tensor(45.2173) 0.4686064318529862\n",
      "epoch: 74 loss: tensor(0.7785) 0.6079632465543645\n",
      "epoch: 74 loss: tensor(0.2384) 0.6140888208269525\n",
      "epoch: 75 loss: tensor(29.4113) 0.5895865237366003\n",
      "epoch: 75 loss: tensor(22.3874) 0.4241960183767228\n",
      "epoch: 75 loss: tensor(11.4647) 0.6140888208269525\n",
      "epoch: 75 loss: tensor(11.8717) 0.7427258805513017\n",
      "epoch: 75 loss: tensor(0.7067) 0.6447166921898928\n",
      "epoch: 75 loss: tensor(0.1823) 0.6049004594180705\n",
      "epoch: 75 loss: tensor(0.2455) 0.555895865237366\n",
      "epoch: 75 loss: tensor(5.0631) 0.6110260336906586\n",
      "epoch: 75 loss: tensor(10.7093) 0.6983154670750383\n",
      "epoch: 75 loss: tensor(4.3311) 0.6937212863705973\n",
      "epoch: 75 loss: tensor(19.1054) 0.6906584992343032\n",
      "epoch: 75 loss: tensor(11.6576) 0.6952526799387443\n",
      "epoch: 75 loss: tensor(3.8102) 0.6967840735068913\n",
      "epoch: 75 loss: tensor(11.5089) 0.6967840735068913\n",
      "epoch: 75 loss: tensor(7.9414) 0.6998468606431854\n",
      "epoch: 75 loss: tensor(5.7974) 0.6967840735068913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 loss: tensor(1.7766) 0.6983154670750383\n",
      "epoch: 75 loss: tensor(0.7484) 0.6967840735068913\n",
      "epoch: 75 loss: tensor(7.7162) 0.7029096477794793\n",
      "epoch: 75 loss: tensor(4.1038) 0.7090352220520674\n",
      "epoch: 76 loss: tensor(1.1979) 0.7044410413476263\n",
      "epoch: 76 loss: tensor(0.8696) 0.7059724349157733\n",
      "epoch: 76 loss: tensor(2.2506) 0.7044410413476263\n",
      "epoch: 76 loss: tensor(1.2370) 0.7120980091883614\n",
      "epoch: 76 loss: tensor(0.6657) 0.7059724349157733\n",
      "epoch: 76 loss: tensor(0.5739) 0.7059724349157733\n",
      "epoch: 76 loss: tensor(0.4347) 0.6753445635528331\n",
      "epoch: 76 loss: tensor(2.8906) 0.6937212863705973\n",
      "epoch: 76 loss: tensor(8.6894) 0.7105666156202144\n",
      "epoch: 76 loss: tensor(2.3499) 0.7120980091883614\n",
      "epoch: 76 loss: tensor(14.1393) 0.7136294027565084\n",
      "epoch: 76 loss: tensor(7.1395) 0.7197549770290965\n",
      "epoch: 76 loss: tensor(1.6944) 0.7197549770290965\n",
      "epoch: 76 loss: tensor(7.2778) 0.7304747320061256\n",
      "epoch: 76 loss: tensor(3.6745) 0.7411944869831547\n",
      "epoch: 76 loss: tensor(2.3561) 0.7442572741194488\n",
      "epoch: 76 loss: tensor(1.0730) 0.7381316998468607\n",
      "epoch: 76 loss: tensor(0.7465) 0.7258805513016845\n",
      "epoch: 76 loss: tensor(1.8828) 0.7565084226646248\n",
      "epoch: 76 loss: tensor(0.2872) 0.7611026033690659\n",
      "epoch: 77 loss: tensor(1.2494) 0.7366003062787136\n",
      "epoch: 77 loss: tensor(0.4630) 0.666156202143951\n",
      "epoch: 77 loss: tensor(1.3379) 0.7457886676875957\n",
      "epoch: 77 loss: tensor(0.7198) 0.7457886676875957\n",
      "epoch: 77 loss: tensor(0.6197) 0.7565084226646248\n",
      "epoch: 77 loss: tensor(0.5433) 0.7258805513016845\n",
      "epoch: 77 loss: tensor(0.3892) 0.678407350689127\n",
      "epoch: 77 loss: tensor(0.8289) 0.7411944869831547\n",
      "epoch: 77 loss: tensor(1.8171) 0.6140888208269525\n",
      "epoch: 77 loss: tensor(6.8604) 0.6094946401225115\n",
      "epoch: 77 loss: tensor(0.1421) 0.6125574272588055\n",
      "epoch: 77 loss: tensor(0.0997) 0.6140888208269525\n",
      "epoch: 77 loss: tensor(0.0938) 0.6125574272588055\n",
      "epoch: 77 loss: tensor(0.2192) 0.6079632465543645\n",
      "epoch: 77 loss: tensor(22.6667) 0.6125574272588055\n",
      "epoch: 77 loss: tensor(11.4217) 0.6186830015313936\n",
      "epoch: 77 loss: tensor(23.8167) 0.5298621745788668\n",
      "epoch: 77 loss: tensor(8.7154) 0.5114854517611026\n",
      "epoch: 77 loss: tensor(13.0047) 0.6998468606431854\n",
      "epoch: 77 loss: tensor(7.0221) 0.6860643185298622\n",
      "epoch: 78 loss: tensor(0.7998) 0.6998468606431854\n",
      "epoch: 78 loss: tensor(0.5218) 0.663093415007657\n",
      "epoch: 78 loss: tensor(3.9474) 0.6906584992343032\n",
      "epoch: 78 loss: tensor(1.8501) 0.6891271056661562\n",
      "epoch: 78 loss: tensor(0.5924) 0.6952526799387443\n",
      "epoch: 78 loss: tensor(0.5437) 0.6906584992343032\n",
      "epoch: 78 loss: tensor(0.4230) 0.6600306278713629\n",
      "epoch: 78 loss: tensor(4.9659) 0.6845329249617151\n",
      "epoch: 78 loss: tensor(10.3838) 0.6952526799387443\n",
      "epoch: 78 loss: tensor(4.3829) 0.6921898928024502\n",
      "epoch: 78 loss: tensor(19.1384) 0.6875957120980092\n",
      "epoch: 78 loss: tensor(11.7310) 0.6952526799387443\n",
      "epoch: 78 loss: tensor(3.8672) 0.6967840735068913\n",
      "epoch: 78 loss: tensor(11.5830) 0.6952526799387443\n",
      "epoch: 78 loss: tensor(8.0114) 0.6998468606431854\n",
      "epoch: 78 loss: tensor(5.8439) 0.6967840735068913\n",
      "epoch: 78 loss: tensor(1.7938) 0.6967840735068913\n",
      "epoch: 78 loss: tensor(0.7634) 0.6967840735068913\n",
      "epoch: 78 loss: tensor(7.8694) 0.7044410413476263\n",
      "epoch: 78 loss: tensor(4.1836) 0.7075038284839203\n",
      "epoch: 79 loss: tensor(1.2129) 0.7029096477794793\n",
      "epoch: 79 loss: tensor(0.8749) 0.7075038284839203\n",
      "epoch: 79 loss: tensor(2.3020) 0.7044410413476263\n",
      "epoch: 79 loss: tensor(1.2525) 0.7090352220520674\n",
      "epoch: 79 loss: tensor(0.6704) 0.7029096477794793\n",
      "epoch: 79 loss: tensor(0.5810) 0.7059724349157733\n",
      "epoch: 79 loss: tensor(0.4457) 0.6738131699846861\n",
      "epoch: 79 loss: tensor(2.9848) 0.6937212863705973\n",
      "epoch: 79 loss: tensor(8.7665) 0.7105666156202144\n",
      "epoch: 79 loss: tensor(2.4248) 0.7136294027565084\n",
      "epoch: 79 loss: tensor(14.3182) 0.7120980091883614\n",
      "epoch: 79 loss: tensor(7.2993) 0.7182235834609495\n",
      "epoch: 79 loss: tensor(1.7703) 0.7182235834609495\n",
      "epoch: 79 loss: tensor(7.4710) 0.7289433384379785\n",
      "epoch: 79 loss: tensor(3.8533) 0.7366003062787136\n",
      "epoch: 79 loss: tensor(2.5077) 0.7396630934150077\n",
      "epoch: 79 loss: tensor(1.0820) 0.7335375191424196\n",
      "epoch: 79 loss: tensor(0.7617) 0.7212863705972435\n",
      "epoch: 79 loss: tensor(2.0389) 0.7580398162327718\n",
      "epoch: 79 loss: tensor(0.3167) 0.7687595712098009\n",
      "epoch: 80 loss: tensor(1.2003) 0.7534456355283308\n",
      "epoch: 80 loss: tensor(0.5111) 0.669218989280245\n",
      "epoch: 80 loss: tensor(1.2224) 0.7473200612557427\n",
      "epoch: 80 loss: tensor(0.7166) 0.7519142419601837\n",
      "epoch: 80 loss: tensor(0.6040) 0.7565084226646248\n",
      "epoch: 80 loss: tensor(0.5444) 0.7274119448698315\n",
      "epoch: 80 loss: tensor(0.3798) 0.6738131699846861\n",
      "epoch: 80 loss: tensor(0.7591) 0.7473200612557427\n",
      "epoch: 80 loss: tensor(1.3577) 0.6156202143950995\n",
      "epoch: 80 loss: tensor(6.8554) 0.6110260336906586\n",
      "epoch: 80 loss: tensor(0.1400) 0.6125574272588055\n",
      "epoch: 80 loss: tensor(0.0975) 0.6156202143950995\n",
      "epoch: 80 loss: tensor(0.0915) 0.6110260336906586\n",
      "epoch: 80 loss: tensor(0.2149) 0.6079632465543645\n",
      "epoch: 80 loss: tensor(22.6609) 0.6110260336906586\n",
      "epoch: 80 loss: tensor(11.5304) 0.6140888208269525\n",
      "epoch: 80 loss: tensor(26.5686) 0.5130168453292496\n",
      "epoch: 80 loss: tensor(26.7655) 0.5635528330781011\n",
      "epoch: 80 loss: tensor(3.0650) 0.7733537519142419\n",
      "epoch: 80 loss: tensor(0.2841) 0.7549770290964778\n",
      "epoch: 81 loss: tensor(1.1515) 0.7166921898928025\n",
      "epoch: 81 loss: tensor(0.3205) 0.6447166921898928\n",
      "epoch: 81 loss: tensor(1.6451) 0.7381316998468607\n",
      "epoch: 81 loss: tensor(0.7674) 0.7442572741194488\n",
      "epoch: 81 loss: tensor(0.6361) 0.7381316998468607\n",
      "epoch: 81 loss: tensor(0.5472) 0.7258805513016845\n",
      "epoch: 81 loss: tensor(0.4085) 0.6768759571209801\n",
      "epoch: 81 loss: tensor(1.1126) 0.7258805513016845\n",
      "epoch: 81 loss: tensor(3.3893) 0.6814701378254211\n",
      "epoch: 81 loss: tensor(3.7367) 0.7626339969372129\n",
      "epoch: 81 loss: tensor(3.2894) 0.5957120980091883\n",
      "epoch: 81 loss: tensor(0.0588) 0.5957120980091883\n",
      "epoch: 81 loss: tensor(0.0525) 0.5957120980091883\n",
      "epoch: 81 loss: tensor(0.1801) 0.5957120980091883\n",
      "epoch: 81 loss: tensor(22.8962) 0.6079632465543645\n",
      "epoch: 81 loss: tensor(20.0464) 0.6094946401225115\n",
      "epoch: 81 loss: tensor(33.4676) 0.55895865237366\n",
      "epoch: 81 loss: tensor(45.1619) 0.4686064318529862\n",
      "epoch: 81 loss: tensor(0.7894) 0.6094946401225115\n",
      "epoch: 81 loss: tensor(0.2339) 0.6110260336906586\n",
      "epoch: 82 loss: tensor(29.3881) 0.5880551301684533\n",
      "epoch: 82 loss: tensor(22.2216) 0.4318529862174579\n",
      "epoch: 82 loss: tensor(11.4178) 0.6171516079632465\n",
      "epoch: 82 loss: tensor(11.6668) 0.7856049004594181\n",
      "epoch: 82 loss: tensor(0.3253) 0.7212863705972435\n",
      "epoch: 82 loss: tensor(0.2445) 0.6569678407350689\n",
      "epoch: 82 loss: tensor(0.2729) 0.5972434915773354\n",
      "epoch: 82 loss: tensor(0.8008) 0.7120980091883614\n",
      "epoch: 82 loss: tensor(1.3485) 0.6125574272588055\n",
      "epoch: 82 loss: tensor(6.8608) 0.6110260336906586\n",
      "epoch: 82 loss: tensor(0.1477) 0.6156202143950995\n",
      "epoch: 82 loss: tensor(0.1032) 0.6140888208269525\n",
      "epoch: 82 loss: tensor(0.0956) 0.6125574272588055\n",
      "epoch: 82 loss: tensor(0.2213) 0.6079632465543645\n",
      "epoch: 82 loss: tensor(22.6691) 0.6125574272588055\n",
      "epoch: 82 loss: tensor(11.5664) 0.6140888208269525\n",
      "epoch: 82 loss: tensor(26.6288) 0.49157733537519144\n",
      "epoch: 82 loss: tensor(26.9163) 0.552833078101072\n",
      "epoch: 82 loss: tensor(3.0596) 0.777947932618683\n",
      "epoch: 82 loss: tensor(0.2925) 0.7366003062787136\n",
      "epoch: 83 loss: tensor(1.2243) 0.6830015313935681\n",
      "epoch: 83 loss: tensor(0.2565) 0.6186830015313936\n",
      "epoch: 83 loss: tensor(3.4006) 0.6967840735068913\n",
      "epoch: 83 loss: tensor(1.4773) 0.7013782542113323\n",
      "epoch: 83 loss: tensor(0.6142) 0.7013782542113323\n",
      "epoch: 83 loss: tensor(0.5429) 0.6967840735068913\n",
      "epoch: 83 loss: tensor(0.4161) 0.666156202143951\n",
      "epoch: 83 loss: tensor(3.6404) 0.6891271056661562\n",
      "epoch: 83 loss: tensor(9.3059) 0.6998468606431854\n",
      "epoch: 83 loss: tensor(3.0357) 0.7029096477794793\n",
      "epoch: 83 loss: tensor(15.7357) 0.7029096477794793\n",
      "epoch: 83 loss: tensor(8.5970) 0.7090352220520674\n",
      "epoch: 83 loss: tensor(2.3752) 0.7151607963246555\n",
      "epoch: 83 loss: tensor(8.9901) 0.7166921898928025\n",
      "epoch: 83 loss: tensor(5.4369) 0.7182235834609495\n",
      "epoch: 83 loss: tensor(4.0487) 0.7166921898928025\n",
      "epoch: 83 loss: tensor(1.2886) 0.7166921898928025\n",
      "epoch: 83 loss: tensor(0.7595) 0.7029096477794793\n",
      "epoch: 83 loss: tensor(4.1163) 0.7258805513016845\n",
      "epoch: 83 loss: tensor(1.4732) 0.7366003062787136\n",
      "epoch: 84 loss: tensor(1.0902) 0.7350689127105666\n",
      "epoch: 84 loss: tensor(0.7513) 0.7059724349157733\n",
      "epoch: 84 loss: tensor(1.2031) 0.7427258805513017\n",
      "epoch: 84 loss: tensor(0.7570) 0.7427258805513017\n",
      "epoch: 84 loss: tensor(0.6553) 0.7381316998468607\n",
      "epoch: 84 loss: tensor(0.5611) 0.7335375191424196\n",
      "epoch: 84 loss: tensor(0.4108) 0.6814701378254211\n",
      "epoch: 84 loss: tensor(1.0868) 0.7289433384379785\n",
      "epoch: 84 loss: tensor(3.2870) 0.6600306278713629\n",
      "epoch: 84 loss: tensor(3.8612) 0.7626339969372129\n",
      "epoch: 84 loss: tensor(2.9007) 0.5957120980091883\n",
      "epoch: 84 loss: tensor(0.0606) 0.5957120980091883\n",
      "epoch: 84 loss: tensor(0.0535) 0.5957120980091883\n",
      "epoch: 84 loss: tensor(0.1823) 0.5957120980091883\n",
      "epoch: 84 loss: tensor(22.8992) 0.6079632465543645\n",
      "epoch: 84 loss: tensor(20.0592) 0.6110260336906586\n",
      "epoch: 84 loss: tensor(33.4978) 0.5604900459418071\n",
      "epoch: 84 loss: tensor(45.1929) 0.4670750382848392\n",
      "epoch: 84 loss: tensor(0.7878) 0.6079632465543645\n",
      "epoch: 84 loss: tensor(0.2371) 0.6125574272588055\n",
      "epoch: 85 loss: tensor(29.3953) 0.5895865237366003\n",
      "epoch: 85 loss: tensor(22.2953) 0.42725880551301687\n",
      "epoch: 85 loss: tensor(11.4406) 0.6171516079632465\n",
      "epoch: 85 loss: tensor(11.7515) 0.77947932618683\n",
      "epoch: 85 loss: tensor(0.3720) 0.6921898928024502\n",
      "epoch: 85 loss: tensor(0.2150) 0.6385911179173047\n",
      "epoch: 85 loss: tensor(0.2584) 0.5788667687595712\n",
      "epoch: 85 loss: tensor(1.1256) 0.6799387442572741\n",
      "epoch: 85 loss: tensor(3.1024) 0.6431852986217458\n",
      "epoch: 85 loss: tensor(4.0083) 0.7626339969372129\n",
      "epoch: 85 loss: tensor(2.1022) 0.5957120980091883\n",
      "epoch: 85 loss: tensor(0.0638) 0.5957120980091883\n",
      "epoch: 85 loss: tensor(0.0557) 0.5957120980091883\n",
      "epoch: 85 loss: tensor(0.1859) 0.5957120980091883\n",
      "epoch: 85 loss: tensor(22.8996) 0.6064318529862175\n",
      "epoch: 85 loss: tensor(20.0796) 0.6110260336906586\n",
      "epoch: 85 loss: tensor(33.5461) 0.554364471669219\n",
      "epoch: 85 loss: tensor(45.2069) 0.47013782542113325\n",
      "epoch: 85 loss: tensor(0.7865) 0.6079632465543645\n",
      "epoch: 85 loss: tensor(0.2420) 0.6140888208269525\n",
      "epoch: 86 loss: tensor(29.4096) 0.5880551301684533\n",
      "epoch: 86 loss: tensor(25.0580) 0.42572741194486985\n",
      "epoch: 86 loss: tensor(11.3892) 0.6125574272588055\n",
      "epoch: 86 loss: tensor(14.6951) 0.6355283307810107\n",
      "epoch: 86 loss: tensor(18.3291) 0.6171516079632465\n",
      "epoch: 86 loss: tensor(0.1515) 0.5834609494640123\n",
      "epoch: 86 loss: tensor(0.2172) 0.554364471669219\n",
      "epoch: 86 loss: tensor(2.9733) 0.5987748851454824\n",
      "epoch: 86 loss: tensor(9.0669) 0.7136294027565084\n",
      "epoch: 86 loss: tensor(2.2515) 0.7166921898928025\n",
      "epoch: 86 loss: tensor(13.9204) 0.7120980091883614\n",
      "epoch: 86 loss: tensor(6.9337) 0.7228177641653905\n",
      "epoch: 86 loss: tensor(1.5985) 0.7228177641653905\n",
      "epoch: 86 loss: tensor(7.0204) 0.7320061255742726\n",
      "epoch: 86 loss: tensor(3.4217) 0.7396630934150077\n",
      "epoch: 86 loss: tensor(2.1449) 0.7457886676875957\n",
      "epoch: 86 loss: tensor(1.0545) 0.7427258805513017\n",
      "epoch: 86 loss: tensor(0.7196) 0.7212863705972435\n",
      "epoch: 86 loss: tensor(1.6730) 0.7733537519142419\n",
      "epoch: 86 loss: tensor(0.2582) 0.7105666156202144\n",
      "epoch: 87 loss: tensor(1.6647) 0.6799387442572741\n",
      "epoch: 87 loss: tensor(0.2921) 0.6094946401225115\n",
      "epoch: 87 loss: tensor(6.6483) 0.6875957120980092\n",
      "epoch: 87 loss: tensor(2.9047) 0.6814701378254211\n",
      "epoch: 87 loss: tensor(0.5175) 0.6906584992343032\n",
      "epoch: 87 loss: tensor(0.5291) 0.6814701378254211\n",
      "epoch: 87 loss: tensor(0.4113) 0.655436447166922\n",
      "epoch: 87 loss: tensor(7.0837) 0.6738131699846861\n",
      "epoch: 87 loss: tensor(13.3935) 0.6952526799387443\n",
      "epoch: 87 loss: tensor(6.2443) 0.6906584992343032\n",
      "epoch: 87 loss: tensor(20.9355) 0.6830015313935681\n",
      "epoch: 87 loss: tensor(15.1715) 0.6799387442572741\n",
      "epoch: 87 loss: tensor(6.3884) 0.6814701378254211\n",
      "epoch: 87 loss: tensor(17.0660) 0.678407350689127\n",
      "epoch: 87 loss: tensor(11.6688) 0.6814701378254211\n",
      "epoch: 87 loss: tensor(6.9381) 0.6830015313935681\n",
      "epoch: 87 loss: tensor(3.0858) 0.6830015313935681\n",
      "epoch: 87 loss: tensor(0.8641) 0.6952526799387443\n",
      "epoch: 87 loss: tensor(14.7747) 0.6799387442572741\n",
      "epoch: 87 loss: tensor(10.0809) 0.678407350689127\n",
      "epoch: 88 loss: tensor(1.1856) 0.6845329249617151\n",
      "epoch: 88 loss: tensor(0.8828) 0.6875957120980092\n",
      "epoch: 88 loss: tensor(5.2360) 0.6860643185298622\n",
      "epoch: 88 loss: tensor(2.6003) 0.6814701378254211\n",
      "epoch: 88 loss: tensor(0.5634) 0.6891271056661562\n",
      "epoch: 88 loss: tensor(0.5512) 0.6845329249617151\n",
      "epoch: 88 loss: tensor(0.4262) 0.6584992343032159\n",
      "epoch: 88 loss: tensor(6.9903) 0.678407350689127\n",
      "epoch: 88 loss: tensor(12.5133) 0.6906584992343032\n",
      "epoch: 88 loss: tensor(5.8311) 0.6937212863705973\n",
      "epoch: 88 loss: tensor(20.6174) 0.6830015313935681\n",
      "epoch: 88 loss: tensor(14.2980) 0.6860643185298622\n",
      "epoch: 88 loss: tensor(5.8369) 0.6814701378254211\n",
      "epoch: 88 loss: tensor(15.1759) 0.6830015313935681\n",
      "epoch: 88 loss: tensor(10.9400) 0.6830015313935681\n",
      "epoch: 88 loss: tensor(6.8945) 0.6814701378254211\n",
      "epoch: 88 loss: tensor(2.7290) 0.6891271056661562\n",
      "epoch: 88 loss: tensor(0.8351) 0.6952526799387443\n",
      "epoch: 88 loss: tensor(13.6135) 0.6830015313935681\n",
      "epoch: 88 loss: tensor(8.5461) 0.6845329249617151\n",
      "epoch: 89 loss: tensor(1.1785) 0.6845329249617151\n",
      "epoch: 89 loss: tensor(0.8656) 0.6906584992343032\n",
      "epoch: 89 loss: tensor(4.4870) 0.6906584992343032\n",
      "epoch: 89 loss: tensor(2.2594) 0.6860643185298622\n",
      "epoch: 89 loss: tensor(0.5821) 0.6967840735068913\n",
      "epoch: 89 loss: tensor(0.5532) 0.6891271056661562\n",
      "epoch: 89 loss: tensor(0.4301) 0.6584992343032159\n",
      "epoch: 89 loss: tensor(6.1876) 0.6799387442572741\n",
      "epoch: 89 loss: tensor(11.5603) 0.6967840735068913\n",
      "epoch: 89 loss: tensor(5.3999) 0.6952526799387443\n",
      "epoch: 89 loss: tensor(20.2760) 0.6845329249617151\n",
      "epoch: 89 loss: tensor(13.3817) 0.6875957120980092\n",
      "epoch: 89 loss: tensor(5.2549) 0.6875957120980092\n",
      "epoch: 89 loss: tensor(13.4941) 0.6906584992343032\n",
      "epoch: 89 loss: tensor(10.1158) 0.6891271056661562\n",
      "epoch: 89 loss: tensor(6.8488) 0.6875957120980092\n",
      "epoch: 89 loss: tensor(2.3272) 0.6891271056661562\n",
      "epoch: 89 loss: tensor(0.8108) 0.6952526799387443\n",
      "epoch: 89 loss: tensor(11.4792) 0.6875957120980092\n",
      "epoch: 89 loss: tensor(6.6455) 0.6937212863705973\n",
      "epoch: 90 loss: tensor(1.2249) 0.6875957120980092\n",
      "epoch: 90 loss: tensor(0.8957) 0.6952526799387443\n",
      "epoch: 90 loss: tensor(3.5605) 0.6891271056661562\n",
      "epoch: 90 loss: tensor(1.8770) 0.6891271056661562\n",
      "epoch: 90 loss: tensor(0.5945) 0.6952526799387443\n",
      "epoch: 90 loss: tensor(0.5487) 0.6906584992343032\n",
      "epoch: 90 loss: tensor(0.4300) 0.6600306278713629\n",
      "epoch: 90 loss: tensor(5.0812) 0.6845329249617151\n",
      "epoch: 90 loss: tensor(10.4772) 0.6952526799387443\n",
      "epoch: 90 loss: tensor(4.4832) 0.6921898928024502\n",
      "epoch: 90 loss: tensor(19.2214) 0.6875957120980092\n",
      "epoch: 90 loss: tensor(11.8734) 0.6937212863705973\n",
      "epoch: 90 loss: tensor(3.9744) 0.6983154670750383\n",
      "epoch: 90 loss: tensor(11.7232) 0.6952526799387443\n",
      "epoch: 90 loss: tensor(8.1299) 0.6998468606431854\n",
      "epoch: 90 loss: tensor(5.9114) 0.6967840735068913\n",
      "epoch: 90 loss: tensor(1.8257) 0.6937212863705973\n",
      "epoch: 90 loss: tensor(0.7739) 0.6983154670750383\n",
      "epoch: 90 loss: tensor(8.1015) 0.7029096477794793\n",
      "epoch: 90 loss: tensor(4.3264) 0.7059724349157733\n",
      "epoch: 91 loss: tensor(1.2232) 0.7029096477794793\n",
      "epoch: 91 loss: tensor(0.8806) 0.7059724349157733\n",
      "epoch: 91 loss: tensor(2.3778) 0.7029096477794793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 loss: tensor(1.2988) 0.7090352220520674\n",
      "epoch: 91 loss: tensor(0.6620) 0.6998468606431854\n",
      "epoch: 91 loss: tensor(0.5784) 0.7029096477794793\n",
      "epoch: 91 loss: tensor(0.4486) 0.6722817764165391\n",
      "epoch: 91 loss: tensor(3.1479) 0.6921898928024502\n",
      "epoch: 91 loss: tensor(8.9011) 0.7059724349157733\n",
      "epoch: 91 loss: tensor(2.5644) 0.7090352220520674\n",
      "epoch: 91 loss: tensor(14.6461) 0.7105666156202144\n",
      "epoch: 91 loss: tensor(7.5954) 0.7166921898928025\n",
      "epoch: 91 loss: tensor(1.9092) 0.7197549770290965\n",
      "epoch: 91 loss: tensor(7.8228) 0.7197549770290965\n",
      "epoch: 91 loss: tensor(4.1790) 0.7258805513016845\n",
      "epoch: 91 loss: tensor(2.7707) 0.7381316998468607\n",
      "epoch: 91 loss: tensor(1.1123) 0.7350689127105666\n",
      "epoch: 91 loss: tensor(0.7823) 0.7166921898928025\n",
      "epoch: 91 loss: tensor(2.3027) 0.7488514548238897\n",
      "epoch: 91 loss: tensor(0.3984) 0.7611026033690659\n",
      "epoch: 92 loss: tensor(1.1503) 0.7549770290964778\n",
      "epoch: 92 loss: tensor(0.5622) 0.6768759571209801\n",
      "epoch: 92 loss: tensor(1.1710) 0.7549770290964778\n",
      "epoch: 92 loss: tensor(0.7211) 0.7549770290964778\n",
      "epoch: 92 loss: tensor(0.5988) 0.7580398162327718\n",
      "epoch: 92 loss: tensor(0.5449) 0.7258805513016845\n",
      "epoch: 92 loss: tensor(0.3797) 0.667687595712098\n",
      "epoch: 92 loss: tensor(0.7535) 0.7503828483920367\n",
      "epoch: 92 loss: tensor(1.2923) 0.6156202143950995\n",
      "epoch: 92 loss: tensor(6.8534) 0.6110260336906586\n",
      "epoch: 92 loss: tensor(0.1378) 0.6125574272588055\n",
      "epoch: 92 loss: tensor(0.0956) 0.6156202143950995\n",
      "epoch: 92 loss: tensor(0.0899) 0.6110260336906586\n",
      "epoch: 92 loss: tensor(0.2124) 0.6079632465543645\n",
      "epoch: 92 loss: tensor(22.6574) 0.6094946401225115\n",
      "epoch: 92 loss: tensor(11.5477) 0.6156202143950995\n",
      "epoch: 92 loss: tensor(26.5804) 0.5114854517611026\n",
      "epoch: 92 loss: tensor(26.8133) 0.5620214395099541\n",
      "epoch: 92 loss: tensor(3.0684) 0.7733537519142419\n",
      "epoch: 92 loss: tensor(0.2791) 0.7565084226646248\n",
      "epoch: 93 loss: tensor(1.1450) 0.7182235834609495\n",
      "epoch: 93 loss: tensor(0.3255) 0.6477794793261868\n",
      "epoch: 93 loss: tensor(1.5918) 0.7427258805513017\n",
      "epoch: 93 loss: tensor(0.7536) 0.7442572741194488\n",
      "epoch: 93 loss: tensor(0.6331) 0.7396630934150077\n",
      "epoch: 93 loss: tensor(0.5478) 0.7243491577335375\n",
      "epoch: 93 loss: tensor(0.4105) 0.6738131699846861\n",
      "epoch: 93 loss: tensor(1.0565) 0.7320061255742726\n",
      "epoch: 93 loss: tensor(3.0577) 0.6416539050535988\n",
      "epoch: 93 loss: tensor(3.9260) 0.7641653905053599\n",
      "epoch: 93 loss: tensor(2.5305) 0.5957120980091883\n",
      "epoch: 93 loss: tensor(0.0575) 0.5957120980091883\n",
      "epoch: 93 loss: tensor(0.0516) 0.5957120980091883\n",
      "epoch: 93 loss: tensor(0.1784) 0.5957120980091883\n",
      "epoch: 93 loss: tensor(22.8920) 0.6079632465543645\n",
      "epoch: 93 loss: tensor(20.0869) 0.6094946401225115\n",
      "epoch: 93 loss: tensor(33.5291) 0.557427258805513\n",
      "epoch: 93 loss: tensor(45.2188) 0.47166921898928027\n",
      "epoch: 93 loss: tensor(0.7893) 0.6079632465543645\n",
      "epoch: 93 loss: tensor(0.2328) 0.6125574272588055\n",
      "epoch: 94 loss: tensor(29.4181) 0.5849923430321593\n",
      "epoch: 94 loss: tensor(22.3889) 0.43032159264931086\n",
      "epoch: 94 loss: tensor(11.4473) 0.6140888208269525\n",
      "epoch: 94 loss: tensor(11.8216) 0.7565084226646248\n",
      "epoch: 94 loss: tensor(0.5059) 0.6508422664624809\n",
      "epoch: 94 loss: tensor(0.1963) 0.6125574272588055\n",
      "epoch: 94 loss: tensor(0.2583) 0.5666156202143952\n",
      "epoch: 94 loss: tensor(3.6787) 0.6217457886676876\n",
      "epoch: 94 loss: tensor(9.5771) 0.7013782542113323\n",
      "epoch: 94 loss: tensor(2.9018) 0.7013782542113323\n",
      "epoch: 94 loss: tensor(15.4396) 0.7059724349157733\n",
      "epoch: 94 loss: tensor(8.3146) 0.7136294027565084\n",
      "epoch: 94 loss: tensor(2.2459) 0.7136294027565084\n",
      "epoch: 94 loss: tensor(8.6591) 0.7182235834609495\n",
      "epoch: 94 loss: tensor(4.9445) 0.7228177641653905\n",
      "epoch: 94 loss: tensor(3.5810) 0.7243491577335375\n",
      "epoch: 94 loss: tensor(1.2291) 0.7212863705972435\n",
      "epoch: 94 loss: tensor(0.7799) 0.7075038284839203\n",
      "epoch: 94 loss: tensor(3.5496) 0.7396630934150077\n",
      "epoch: 94 loss: tensor(0.9650) 0.7411944869831547\n",
      "epoch: 95 loss: tensor(1.0701) 0.7427258805513017\n",
      "epoch: 95 loss: tensor(0.6874) 0.6967840735068913\n",
      "epoch: 95 loss: tensor(1.1204) 0.7442572741194488\n",
      "epoch: 95 loss: tensor(0.7165) 0.7457886676875957\n",
      "epoch: 95 loss: tensor(0.6317) 0.7565084226646248\n",
      "epoch: 95 loss: tensor(0.5535) 0.7274119448698315\n",
      "epoch: 95 loss: tensor(0.3999) 0.678407350689127\n",
      "epoch: 95 loss: tensor(0.8500) 0.7411944869831547\n",
      "epoch: 95 loss: tensor(1.9241) 0.6202143950995406\n",
      "epoch: 95 loss: tensor(6.7986) 0.6186830015313936\n",
      "epoch: 95 loss: tensor(0.1642) 0.6217457886676876\n",
      "epoch: 95 loss: tensor(0.0968) 0.6186830015313936\n",
      "epoch: 95 loss: tensor(0.0955) 0.6171516079632465\n",
      "epoch: 95 loss: tensor(0.2238) 0.6140888208269525\n",
      "epoch: 95 loss: tensor(17.3435) 0.6493108728943339\n",
      "epoch: 95 loss: tensor(1.0799) 0.7411944869831547\n",
      "epoch: 95 loss: tensor(0.5443) 0.7228177641653905\n",
      "epoch: 95 loss: tensor(0.4565) 0.666156202143951\n",
      "epoch: 95 loss: tensor(1.4353) 0.6339969372128637\n",
      "epoch: 95 loss: tensor(0.1866) 0.6309341500765697\n",
      "epoch: 96 loss: tensor(8.6723) 0.7166921898928025\n",
      "epoch: 96 loss: tensor(0.3409) 0.6477794793261868\n",
      "epoch: 96 loss: tensor(1.7480) 0.7320061255742726\n",
      "epoch: 96 loss: tensor(0.8040) 0.7427258805513017\n",
      "epoch: 96 loss: tensor(0.6426) 0.7350689127105666\n",
      "epoch: 96 loss: tensor(0.5495) 0.7243491577335375\n",
      "epoch: 96 loss: tensor(0.4124) 0.6768759571209801\n",
      "epoch: 96 loss: tensor(1.2651) 0.7228177641653905\n",
      "epoch: 96 loss: tensor(4.2490) 0.7580398162327718\n",
      "epoch: 96 loss: tensor(0.7288) 0.7641653905053599\n",
      "epoch: 96 loss: tensor(2.3706) 0.5957120980091883\n",
      "epoch: 96 loss: tensor(0.0555) 0.5957120980091883\n",
      "epoch: 96 loss: tensor(0.0481) 0.5941807044410413\n",
      "epoch: 96 loss: tensor(0.1768) 0.5941807044410413\n",
      "epoch: 96 loss: tensor(22.9440) 0.6064318529862175\n",
      "epoch: 96 loss: tensor(20.0867) 0.6079632465543645\n",
      "epoch: 96 loss: tensor(33.5641) 0.5635528330781011\n",
      "epoch: 96 loss: tensor(45.2252) 0.4686064318529862\n",
      "epoch: 96 loss: tensor(0.7740) 0.6094946401225115\n",
      "epoch: 96 loss: tensor(0.2352) 0.6125574272588055\n",
      "epoch: 97 loss: tensor(29.4078) 0.5865237366003063\n",
      "epoch: 97 loss: tensor(22.3476) 0.43032159264931086\n",
      "epoch: 97 loss: tensor(11.4484) 0.6156202143950995\n",
      "epoch: 97 loss: tensor(11.8106) 0.7611026033690659\n",
      "epoch: 97 loss: tensor(0.4564) 0.663093415007657\n",
      "epoch: 97 loss: tensor(0.1969) 0.6171516079632465\n",
      "epoch: 97 loss: tensor(0.2556) 0.5681470137825421\n",
      "epoch: 97 loss: tensor(2.8401) 0.6263399693721287\n",
      "epoch: 97 loss: tensor(8.8865) 0.7105666156202144\n",
      "epoch: 97 loss: tensor(2.1578) 0.7136294027565084\n",
      "epoch: 97 loss: tensor(13.7053) 0.7166921898928025\n",
      "epoch: 97 loss: tensor(6.7370) 0.7243491577335375\n",
      "epoch: 97 loss: tensor(1.5094) 0.7258805513016845\n",
      "epoch: 97 loss: tensor(6.7773) 0.7350689127105666\n",
      "epoch: 97 loss: tensor(3.2013) 0.7442572741194488\n",
      "epoch: 97 loss: tensor(1.9860) 0.7473200612557427\n",
      "epoch: 97 loss: tensor(1.0241) 0.7488514548238897\n",
      "epoch: 97 loss: tensor(0.7226) 0.7228177641653905\n",
      "epoch: 97 loss: tensor(1.4365) 0.7182235834609495\n",
      "epoch: 97 loss: tensor(0.2153) 0.667687595712098\n",
      "epoch: 98 loss: tensor(5.2538) 0.6983154670750383\n",
      "epoch: 98 loss: tensor(0.3010) 0.6355283307810107\n",
      "epoch: 98 loss: tensor(2.8863) 0.7059724349157733\n",
      "epoch: 98 loss: tensor(1.2355) 0.7105666156202144\n",
      "epoch: 98 loss: tensor(0.6481) 0.7044410413476263\n",
      "epoch: 98 loss: tensor(0.5611) 0.7044410413476263\n",
      "epoch: 98 loss: tensor(0.4292) 0.6722817764165391\n",
      "epoch: 98 loss: tensor(2.8495) 0.6952526799387443\n",
      "epoch: 98 loss: tensor(8.6614) 0.7105666156202144\n",
      "epoch: 98 loss: tensor(2.3072) 0.7120980091883614\n",
      "epoch: 98 loss: tensor(14.0423) 0.7136294027565084\n",
      "epoch: 98 loss: tensor(7.0494) 0.7228177641653905\n",
      "epoch: 98 loss: tensor(1.6532) 0.7228177641653905\n",
      "epoch: 98 loss: tensor(7.1737) 0.7304747320061256\n",
      "epoch: 98 loss: tensor(3.5759) 0.7411944869831547\n",
      "epoch: 98 loss: tensor(2.2829) 0.7427258805513017\n",
      "epoch: 98 loss: tensor(1.0600) 0.7381316998468607\n",
      "epoch: 98 loss: tensor(0.7438) 0.7243491577335375\n",
      "epoch: 98 loss: tensor(1.8104) 0.7656967840735069\n",
      "epoch: 98 loss: tensor(0.2679) 0.7549770290964778\n",
      "epoch: 99 loss: tensor(1.2867) 0.7335375191424196\n",
      "epoch: 99 loss: tensor(0.4431) 0.664624808575804\n",
      "epoch: 99 loss: tensor(1.4260) 0.7457886676875957\n",
      "epoch: 99 loss: tensor(0.7333) 0.7457886676875957\n",
      "epoch: 99 loss: tensor(0.6283) 0.7457886676875957\n",
      "epoch: 99 loss: tensor(0.5460) 0.7289433384379785\n",
      "epoch: 99 loss: tensor(0.3995) 0.6753445635528331\n",
      "epoch: 99 loss: tensor(0.9237) 0.7411944869831547\n",
      "epoch: 99 loss: tensor(2.3507) 0.6324655436447167\n",
      "epoch: 99 loss: tensor(4.0980) 0.776416539050536\n",
      "epoch: 99 loss: tensor(1.5562) 0.5957120980091883\n",
      "epoch: 99 loss: tensor(0.0613) 0.5957120980091883\n",
      "epoch: 99 loss: tensor(0.0547) 0.5957120980091883\n",
      "epoch: 99 loss: tensor(0.1826) 0.5957120980091883\n",
      "epoch: 99 loss: tensor(22.8803) 0.6079632465543645\n",
      "epoch: 99 loss: tensor(20.0944) 0.6094946401225115\n",
      "epoch: 99 loss: tensor(33.5492) 0.557427258805513\n",
      "epoch: 99 loss: tensor(45.2260) 0.4670750382848392\n",
      "epoch: 99 loss: tensor(0.7910) 0.6079632465543645\n",
      "epoch: 99 loss: tensor(0.2368) 0.6125574272588055\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for i in range(it):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        \n",
    "        x = X[start:end]\n",
    "        y = Y[start:end]\n",
    "        y_predict = model(x) # 预测值\n",
    "        loss = loss_fn(y_predict,y) #计算损失\n",
    "        \n",
    "        # 梯度置0\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print('epoch:',epoch,'loss:',loss.data,((model(X).data.numpy() > 0.5).astype('int') == Y.numpy()).mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73695a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.1412,  0.0414, -0.0047,  0.0842, -0.0909,  0.0395,  0.2125, -0.2868,\n",
       "                        0.2438, -0.0333, -0.4784,  0.2579,  0.0171,  0.0135, -0.0348]])),\n",
       "             ('0.bias', tensor([-0.1219]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8af271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7182235834609495"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((model(X).data.numpy() > 0.5).astype('int') == Y.numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275166ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d9080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbee6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0231e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb37e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_pytorch",
   "language": "python",
   "name": "m_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
